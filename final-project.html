<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>289009</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<section id="predict-bike-sharing-demand-with-autogluon-template" class="cell markdown" id="arVx8pXyVrGv">
<h1>Predict Bike Sharing Demand with AutoGluon Template</h1>
</section>
<section id="project-predict-bike-sharing-demand-with-autogluon" class="cell markdown" id="lrpESpWHVrGz">
<h2>Project: Predict Bike Sharing Demand with AutoGluon</h2>
<p>This notebook is a template with each step that you need to complete for the project.</p>
<p>Please fill in your code where there are explicit <code>?</code> markers in the notebook. You are welcome to add more cells and code as you see fit.</p>
<p>Once you have completed all the code implementations, please export your notebook as a HTML file so the reviews can view your code. Make sure you have all outputs correctly outputted.</p>
<p><code>File-&gt; Export Notebook As... -&gt; Export Notebook as HTML</code></p>
<p>There is a writeup to complete as well after all code implememtation is done. Please answer all questions and attach the necessary tables and charts. You can complete the writeup in either markdown or PDF.</p>
<p>Completing the code template and writeup template will cover all of the rubric points for this project.</p>
<p>The rubric contains "Stand Out Suggestions" for enhancing the project beyond the minimum requirements. The stand out suggestions are optional. If you decide to pursue the "stand out suggestions", you can include the code in this notebook and also discuss the results in the writeup file.</p>
</section>
<section id="step-1-create-an-account-with-kaggle" class="cell markdown" id="kirWuqB4VrG0">
<h2>Step 1: Create an account with Kaggle</h2>
</section>
<section id="create-kaggle-account-and-download-api-key" class="cell markdown" id="xOYbcKluVrG0">
<h3>Create Kaggle Account and download API key</h3>
<p>Below is example of steps to get the API username and key. Each student will have their own username and key.</p>
</section>
<div class="cell markdown" id="gOo78fS8VrG1">
<ol>
<li>Open account settings. <img src="kaggle1.png" alt="kaggle1.png" /> <img src="kaggle2.png" alt="kaggle2.png" /></li>
<li>Scroll down to API and click Create New API Token. <img src="kaggle3.png" alt="kaggle3.png" /> <img src="kaggle4.png" alt="kaggle4.png" /></li>
<li>Open up <code>kaggle.json</code> and use the username and key. <img src="kaggle5.png" alt="kaggle5.png" /></li>
</ol>
</div>
<section id="step-2-download-the-kaggle-dataset-using-the-kaggle-python-library" class="cell markdown" id="EoaGawbNVrG1">
<h2>Step 2: Download the Kaggle dataset using the kaggle python library</h2>
</section>
<section id="open-up-sagemaker-studio-and-use-starter-template" class="cell markdown" id="eMaxvZ4DVrG1">
<h3>Open up Sagemaker Studio and use starter template</h3>
</section>
<div class="cell markdown" id="VEHHVS4MVrG2">
<ol>
<li>Notebook should be using a <code>ml.t3.medium</code> instance (2 vCPU + 4 GiB)</li>
<li>Notebook should be using kernal: <code>Python 3 (MXNet 1.8 Python 3.7 CPU Optimized)</code></li>
</ol>
</div>
<section id="install-packages" class="cell markdown" id="ViMDseG6VrG2">
<h3>Install packages</h3>
</section>
<div class="cell code" data-execution_count="1" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="LfRsMWsaVrG2" data-outputId="230bcda6-e788-4e77-bce0-7f583f84c96b">
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">-</span>U pip</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">-</span>U setuptools wheel</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">-</span>U <span class="st">&quot;mxnet&lt;2.0.0&quot;</span> bokeh<span class="op">==</span><span class="fl">2.0.1</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install autogluon <span class="op">--</span>no<span class="op">-</span>cache<span class="op">-</span><span class="bu">dir</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Without --no-cache-dir, smaller aws instances may have trouble installing</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (67.8.0)
Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.40.0)
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: mxnet&lt;2.0.0 in /usr/local/lib/python3.10/dist-packages (1.9.1)
Requirement already satisfied: bokeh==2.0.1 in /usr/local/lib/python3.10/dist-packages (2.0.1)
Requirement already satisfied: PyYAML&gt;=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (6.0)
Requirement already satisfied: python-dateutil&gt;=2.1 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (2.8.2)
Requirement already satisfied: Jinja2&gt;=2.7 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (3.1.2)
Requirement already satisfied: numpy&gt;=1.11.3 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (1.22.4)
Requirement already satisfied: pillow&gt;=4.0 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (9.5.0)
Requirement already satisfied: packaging&gt;=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (23.1)
Requirement already satisfied: tornado&gt;=5 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (6.3.1)
Requirement already satisfied: typing-extensions&gt;=3.7.4 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (4.5.0)
Requirement already satisfied: requests&lt;3,&gt;=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet&lt;2.0.0) (2.27.1)
Requirement already satisfied: graphviz&lt;0.9.0,&gt;=0.8.1 in /usr/local/lib/python3.10/dist-packages (from mxnet&lt;2.0.0) (0.8.4)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2&gt;=2.7-&gt;bokeh==2.0.1) (2.1.2)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil&gt;=2.1-&gt;bokeh==2.0.1) (1.16.0)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet&lt;2.0.0) (1.26.15)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet&lt;2.0.0) (2022.12.7)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet&lt;2.0.0) (2.0.12)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet&lt;2.0.0) (3.4)
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: autogluon in /usr/local/lib/python3.10/dist-packages (0.7.0)
Requirement already satisfied: autogluon.core[all]==0.7.0 in /usr/local/lib/python3.10/dist-packages (from autogluon) (0.7.0)
Requirement already satisfied: autogluon.features==0.7.0 in /usr/local/lib/python3.10/dist-packages (from autogluon) (0.7.0)
Requirement already satisfied: autogluon.tabular[all]==0.7.0 in /usr/local/lib/python3.10/dist-packages (from autogluon) (0.7.0)
Requirement already satisfied: autogluon.multimodal==0.7.0 in /usr/local/lib/python3.10/dist-packages (from autogluon) (0.7.0)
Requirement already satisfied: autogluon.timeseries[all]==0.7.0 in /usr/local/lib/python3.10/dist-packages (from autogluon) (0.7.0)
Requirement already satisfied: numpy&lt;1.27,&gt;=1.21 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (1.22.4)
Requirement already satisfied: scipy&lt;1.12,&gt;=1.5.4 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (1.10.1)
Requirement already satisfied: scikit-learn&lt;1.3,&gt;=1.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (1.2.2)
Requirement already satisfied: networkx&lt;3.0,&gt;=2.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (2.8.8)
Requirement already satisfied: pandas&lt;1.6,&gt;=1.4.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (1.5.3)
Requirement already satisfied: tqdm&lt;5,&gt;=4.38 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (4.65.0)
Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (2.27.1)
Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (3.7.1)
Requirement already satisfied: boto3&lt;2,&gt;=1.10 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (1.26.144)
Requirement already satisfied: autogluon.common==0.7.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (0.7.0)
Requirement already satisfied: hyperopt&lt;0.2.8,&gt;=0.2.7 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (0.2.7)
Requirement already satisfied: ray[tune]&lt;2.3,&gt;=2.2 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (2.2.0)
Requirement already satisfied: Pillow&lt;9.6,&gt;=9.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (9.5.0)
Requirement already satisfied: jsonschema&lt;4.18,&gt;=4.14 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (4.17.3)
Requirement already satisfied: seqeval&lt;1.3.0,&gt;=1.2.2 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (1.2.2)
Requirement already satisfied: evaluate&lt;0.4.0,&gt;=0.2.2 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (0.3.0)
Requirement already satisfied: accelerate&lt;0.17,&gt;=0.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (0.16.0)
Requirement already satisfied: timm&lt;0.7.0,&gt;=0.6.12 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (0.6.13)
Requirement already satisfied: torch&lt;1.14,&gt;=1.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (1.13.1)
Requirement already satisfied: torchvision&lt;0.15.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (0.14.1)
Requirement already satisfied: fairscale&lt;0.4.14,&gt;=0.4.5 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (0.4.13)
Requirement already satisfied: scikit-image&lt;0.20.0,&gt;=0.19.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (0.19.3)
Requirement already satisfied: pytorch-lightning&lt;1.10.0,&gt;=1.9.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (1.9.5)
Requirement already satisfied: text-unidecode&lt;1.4,&gt;=1.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (1.3)
Requirement already satisfied: torchmetrics&lt;0.9.0,&gt;=0.8.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (0.8.2)
Requirement already satisfied: transformers&lt;4.27.0,&gt;=4.23.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (4.26.1)
Requirement already satisfied: nptyping&lt;2.5.0,&gt;=1.4.4 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (2.4.1)
Requirement already satisfied: omegaconf&lt;2.3.0,&gt;=2.1.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (2.2.3)
Requirement already satisfied: sentencepiece&lt;0.2.0,&gt;=0.1.95 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (0.1.99)
Requirement already satisfied: pytorch-metric-learning&lt;2.0,&gt;=1.3.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (1.7.3)
Requirement already satisfied: nlpaug&lt;1.2.0,&gt;=1.1.10 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (1.1.11)
Requirement already satisfied: nltk&lt;4.0.0,&gt;=3.4.5 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (3.8.1)
Requirement already satisfied: openmim&lt;0.4.0,&gt;0.1.5 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (0.3.7)
Requirement already satisfied: defusedxml&lt;0.7.2,&gt;=0.7.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (0.7.1)
Requirement already satisfied: jinja2&lt;3.2,&gt;=3.0.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (3.1.2)
Requirement already satisfied: tensorboard&lt;3,&gt;=2.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (2.12.2)
Requirement already satisfied: pytesseract&lt;0.3.11,&gt;=0.3.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (0.3.10)
Requirement already satisfied: catboost&lt;1.2,&gt;=1.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.1.1)
Requirement already satisfied: lightgbm&lt;3.4,&gt;=3.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.7.0-&gt;autogluon) (3.3.5)
Requirement already satisfied: xgboost&lt;1.8,&gt;=1.6 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.7.5)
Requirement already satisfied: fastai&lt;2.8,&gt;=2.3.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.7.0-&gt;autogluon) (2.7.12)
Requirement already satisfied: joblib&lt;2,&gt;=1.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.7.0-&gt;autogluon) (1.2.0)
Requirement already satisfied: statsmodels&lt;0.14,&gt;=0.13.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.13.5)
Requirement already satisfied: gluonts&lt;0.13,&gt;=0.12.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.12.8)
Requirement already satisfied: statsforecast&lt;1.5,&gt;=1.4.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.7.0-&gt;autogluon) (1.4.0)
Requirement already satisfied: ujson&lt;6,&gt;=5 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.7.0-&gt;autogluon) (5.7.0)
Requirement already satisfied: sktime&lt;0.16,&gt;=0.14 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.15.1)
Requirement already satisfied: tbats&lt;2,&gt;=1.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.7.0-&gt;autogluon) (1.1.3)
Requirement already satisfied: pmdarima&lt;1.9,&gt;=1.8.2 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.7.0-&gt;autogluon) (1.8.5)
Requirement already satisfied: psutil&lt;6,&gt;=5.7.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.common==0.7.0-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (5.9.5)
Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from autogluon.common==0.7.0-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (67.8.0)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate&lt;0.17,&gt;=0.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (23.1)
Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate&lt;0.17,&gt;=0.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (6.0)
Requirement already satisfied: botocore&lt;1.30.0,&gt;=1.29.144 in /usr/local/lib/python3.10/dist-packages (from boto3&lt;2,&gt;=1.10-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.29.144)
Requirement already satisfied: jmespath&lt;2.0.0,&gt;=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3&lt;2,&gt;=1.10-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.0.1)
Requirement already satisfied: s3transfer&lt;0.7.0,&gt;=0.6.0 in /usr/local/lib/python3.10/dist-packages (from boto3&lt;2,&gt;=1.10-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (0.6.1)
Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost&lt;1.2,&gt;=1.0-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.8.4)
Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost&lt;1.2,&gt;=1.0-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (5.13.1)
Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost&lt;1.2,&gt;=1.0-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.16.0)
Requirement already satisfied: datasets&gt;=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.12.0)
Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.3.6)
Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (3.2.0)
Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.70.14)
Requirement already satisfied: fsspec[http]&gt;=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2023.4.0)
Requirement already satisfied: huggingface-hub&gt;=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.14.1)
Requirement already satisfied: responses&lt;0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.18.0)
Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (23.1.2)
Requirement already satisfied: fastdownload&lt;2,&gt;=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.0.7)
Requirement already satisfied: fastcore&lt;1.6,&gt;=1.5.29 in /usr/local/lib/python3.10/dist-packages (from fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.5.29)
Requirement already satisfied: fastprogress&gt;=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.0.3)
Requirement already satisfied: spacy&lt;4 in /usr/local/lib/python3.10/dist-packages (from fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (3.5.2)
Requirement already satisfied: pydantic~=1.7 in /usr/local/lib/python3.10/dist-packages (from gluonts&lt;0.13,&gt;=0.12.0-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (1.10.7)
Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.10/dist-packages (from gluonts&lt;0.13,&gt;=0.12.0-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.12.0)
Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gluonts&lt;0.13,&gt;=0.12.0-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (4.5.0)
Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt&lt;0.2.8,&gt;=0.2.7-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (0.18.3)
Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt&lt;0.2.8,&gt;=0.2.7-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2.2.1)
Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt&lt;0.2.8,&gt;=0.2.7-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (0.10.9.7)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2&lt;3.2,&gt;=3.0.3-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.1.2)
Requirement already satisfied: attrs&gt;=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema&lt;4.18,&gt;=4.14-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (23.1.0)
Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,&gt;=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema&lt;4.18,&gt;=4.14-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.19.3)
Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from lightgbm&lt;3.4,&gt;=3.3-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.40.0)
Requirement already satisfied: gdown&gt;=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug&lt;1.2.0,&gt;=1.1.10-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (4.6.6)
Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk&lt;4.0.0,&gt;=3.4.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (8.1.3)
Requirement already satisfied: regex&gt;=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk&lt;4.0.0,&gt;=3.4.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2022.10.31)
Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf&lt;2.3.0,&gt;=2.1.1-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (4.9.3)
Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.4.6)
Requirement already satisfied: model-index in /usr/local/lib/python3.10/dist-packages (from openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.1.11)
Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (13.3.4)
Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.8.10)
Requirement already satisfied: python-dateutil&gt;=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas&lt;1.6,&gt;=1.4.1-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2.8.2)
Requirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas&lt;1.6,&gt;=1.4.1-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2022.7.1)
Requirement already satisfied: Cython!=0.29.18,&gt;=0.29 in /usr/local/lib/python3.10/dist-packages (from pmdarima&lt;1.9,&gt;=1.8.2-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.29.34)
Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from pmdarima&lt;1.9,&gt;=1.8.2-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (1.26.15)
Requirement already satisfied: lightning-utilities&gt;=0.6.0.post0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning&lt;1.10.0,&gt;=1.9.0-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.8.0)
Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.12.0)
Requirement already satisfied: msgpack&lt;2.0.0,&gt;=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.0.5)
Requirement already satisfied: protobuf!=3.19.5,&gt;=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.20.3)
Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.3.1)
Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.3.3)
Requirement already satisfied: virtualenv&gt;=20.0.24 in /usr/local/lib/python3.10/dist-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (20.23.0)
Requirement already satisfied: grpcio&gt;=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.54.0)
Requirement already satisfied: tensorboardX&gt;=1.9 in /usr/local/lib/python3.10/dist-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2.6)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2022.12.7)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2.0.12)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.4)
Requirement already satisfied: imageio&gt;=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image&lt;0.20.0,&gt;=0.19.1-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.25.1)
Requirement already satisfied: tifffile&gt;=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image&lt;0.20.0,&gt;=0.19.1-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2023.4.12)
Requirement already satisfied: PyWavelets&gt;=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image&lt;0.20.0,&gt;=0.19.1-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (1.4.1)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn&lt;1.3,&gt;=1.0-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.1.0)
Requirement already satisfied: deprecated&gt;=1.2.13 in /usr/local/lib/python3.10/dist-packages (from sktime&lt;0.16,&gt;=0.14-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (1.2.14)
Requirement already satisfied: numba&gt;=0.55 in /usr/local/lib/python3.10/dist-packages (from sktime&lt;0.16,&gt;=0.14-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.56.4)
Requirement already satisfied: patsy&gt;=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels&lt;0.14,&gt;=0.13.0-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.5.3)
Requirement already satisfied: absl-py&gt;=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (1.4.0)
Requirement already satisfied: google-auth&lt;3,&gt;=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.17.3)
Requirement already satisfied: google-auth-oauthlib&lt;1.1,&gt;=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (1.0.0)
Requirement already satisfied: markdown&gt;=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (3.4.3)
Requirement already satisfied: tensorboard-data-server&lt;0.8.0,&gt;=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.7.0)
Requirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (1.8.1)
Requirement already satisfied: werkzeug&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.3.0)
Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch&lt;1.14,&gt;=1.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (11.7.99)
Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch&lt;1.14,&gt;=1.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (8.5.0.96)
Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch&lt;1.14,&gt;=1.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (11.10.3.66)
Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch&lt;1.14,&gt;=1.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (11.7.99)
Requirement already satisfied: pyDeprecate==0.3.* in /usr/local/lib/python3.10/dist-packages (from torchmetrics&lt;0.9.0,&gt;=0.8.0-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.3.2)
Requirement already satisfied: tokenizers!=0.11.3,&lt;0.14,&gt;=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers&lt;4.27.0,&gt;=4.23.0-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.13.3)
Requirement already satisfied: contourpy&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.0.7)
Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (0.11.0)
Requirement already satisfied: fonttools&gt;=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (4.39.3)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.4.4)
Requirement already satisfied: pyparsing&gt;=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.0.9)
Requirement already satisfied: pyarrow&gt;=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets&gt;=2.0.0-&gt;evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (9.0.0)
Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets&gt;=2.0.0-&gt;evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (3.8.4)
Requirement already satisfied: wrapt&lt;2,&gt;=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated&gt;=1.2.13-&gt;sktime&lt;0.16,&gt;=0.14-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (1.14.1)
Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown&gt;=4.0.0-&gt;nlpaug&lt;1.2.0,&gt;=1.1.10-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (4.11.2)
Requirement already satisfied: cachetools&lt;6.0,&gt;=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (5.3.0)
Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.3.0)
Requirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (4.9)
Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib&lt;1.1,&gt;=0.5-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (1.3.1)
Requirement already satisfied: llvmlite&lt;0.40,&gt;=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba&gt;=0.55-&gt;sktime&lt;0.16,&gt;=0.14-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.39.1)
Requirement already satisfied: spacy-legacy&lt;3.1.0,&gt;=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (3.0.12)
Requirement already satisfied: spacy-loggers&lt;2.0.0,&gt;=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.0.4)
Requirement already satisfied: murmurhash&lt;1.1.0,&gt;=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.0.9)
Requirement already satisfied: cymem&lt;2.1.0,&gt;=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (2.0.7)
Requirement already satisfied: preshed&lt;3.1.0,&gt;=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (3.0.8)
Requirement already satisfied: thinc&lt;8.2.0,&gt;=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (8.1.9)
Requirement already satisfied: wasabi&lt;1.2.0,&gt;=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.1.1)
Requirement already satisfied: srsly&lt;3.0.0,&gt;=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (2.4.6)
Requirement already satisfied: catalogue&lt;2.1.0,&gt;=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (2.0.8)
Requirement already satisfied: typer&lt;0.8.0,&gt;=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.7.0)
Requirement already satisfied: pathy&gt;=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.10.1)
Requirement already satisfied: smart-open&lt;7.0.0,&gt;=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (6.3.0)
Requirement already satisfied: langcodes&lt;4.0.0,&gt;=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (3.3.0)
Requirement already satisfied: distlib&lt;1,&gt;=0.3.6 in /usr/local/lib/python3.10/dist-packages (from virtualenv&gt;=20.0.24-&gt;ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (0.3.6)
Requirement already satisfied: platformdirs&lt;4,&gt;=3.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv&gt;=20.0.24-&gt;ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.3.0)
Requirement already satisfied: ordered-set in /usr/local/lib/python3.10/dist-packages (from model-index-&gt;openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (4.1.0)
Requirement already satisfied: tenacity&gt;=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly-&gt;catboost&lt;1.2,&gt;=1.0-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (8.2.2)
Requirement already satisfied: markdown-it-py&lt;3.0.0,&gt;=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich-&gt;openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.2.0)
Requirement already satisfied: pygments&lt;3.0.0,&gt;=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich-&gt;openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.14.0)
Requirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;datasets&gt;=2.0.0-&gt;evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (6.0.4)
Requirement already satisfied: async-timeout&lt;5.0,&gt;=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;datasets&gt;=2.0.0-&gt;evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (4.0.2)
Requirement already satisfied: yarl&lt;2.0,&gt;=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;datasets&gt;=2.0.0-&gt;evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (1.9.2)
Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py&lt;3.0.0,&gt;=2.2.0-&gt;rich-&gt;openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.1.2)
Requirement already satisfied: pyasn1&lt;0.6.0,&gt;=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.5.0)
Requirement already satisfied: oauthlib&gt;=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;1.1,&gt;=0.5-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (3.2.2)
Requirement already satisfied: blis&lt;0.8.0,&gt;=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc&lt;8.2.0,&gt;=8.1.8-&gt;spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.7.9)
Requirement already satisfied: confection&lt;1.0.0,&gt;=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc&lt;8.2.0,&gt;=8.1.8-&gt;spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.0.4)
Requirement already satisfied: soupsieve&gt;1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4-&gt;gdown&gt;=4.0.0-&gt;nlpaug&lt;1.2.0,&gt;=1.1.10-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.4.1)
Requirement already satisfied: PySocks!=1.5.7,&gt;=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.7.1)
</code></pre>
</div>
</div>
<section id="setup-kaggle-api-key" class="cell markdown" id="G_sIEBVyVrG4">
<h3>Setup Kaggle API Key</h3>
</section>
<div class="cell code" data-execution_count="2" id="6Pzt15MCVrG4">
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create the .kaggle directory and an empty kaggle.json file</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>mkdir <span class="op">-</span>p <span class="op">/</span>root<span class="op">/</span>.kaggle</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>touch <span class="op">/</span>root<span class="op">/</span>.kaggle<span class="op">/</span>kaggle.json</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>chmod <span class="dv">600</span> <span class="op">/</span>root<span class="op">/</span>.kaggle<span class="op">/</span>kaggle.json</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="3" id="Vb8REqmMVrG5">
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fill in your user name and key from creating the kaggle account and API token file</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>kaggle_username <span class="op">=</span> <span class="st">&quot;KAGGLE_USERNAME&quot;</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>kaggle_key <span class="op">=</span> <span class="st">&quot;KAGGLE_KEY&quot;</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Save API token the kaggle.json file</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">&quot;/root/.kaggle/kaggle.json&quot;</span>, <span class="st">&quot;w&quot;</span>) <span class="im">as</span> f:</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    f.write(json.dumps({<span class="st">&quot;username&quot;</span>: kaggle_username, <span class="st">&quot;key&quot;</span>: kaggle_key}))</span></code></pre></div>
</div>
<section id="download-and-explore-dataset" class="cell markdown" id="3j4KKderVrG5">
<h3>Download and explore dataset</h3>
</section>
<section id="go-to-the-bike-sharing-demand-competition-and-agree-to-the-terms" class="cell markdown" id="Fk4kixyuVrG5">
<h3>Go to the bike sharing demand competition and agree to the terms</h3>
<p><img src="kaggle6.png" alt="kaggle6.png" /></p>
</section>
<div class="cell code" data-execution_count="4" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="F6DlwNIPVrG5" data-outputId="df3f76e1-607b-499e-8be0-7a137734f288">
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Download the dataset, it will be in a .zip file so you&#39;ll need to unzip it as well.</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions download <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># If you already downloaded it you can use the -o command to overwrite the file</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>unzip <span class="op">-</span>o bike<span class="op">-</span>sharing<span class="op">-</span>demand.<span class="bu">zip</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Downloading bike-sharing-demand.zip to /content
100% 189k/189k [00:00&lt;00:00, 490kB/s]
100% 189k/189k [00:00&lt;00:00, 490kB/s]
Archive:  bike-sharing-demand.zip
  inflating: sampleSubmission.csv    
  inflating: test.csv                
  inflating: train.csv               
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="5" id="gliz1FSPVrG5">
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> autogluon.tabular <span class="im">import</span> TabularPredictor</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="10" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:443}" id="jMwiiq2WVrG5" data-outputId="03a6ebfe-fb7b-4512-cf31-fabd54a518de">
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the train dataset in pandas by reading the csv</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the parsing of the datetime column so you can use some of the `dt` features in pandas later</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>train <span class="op">=</span> pd.read_csv(<span class="st">&#39;train.csv&#39;</span>, parse_dates<span class="op">=</span>[<span class="st">&quot;datetime&quot;</span>])</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>train.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="10">

  <div id="df-4d02188e-d985-488e-b9ed-36d4f936a3c2">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>datetime</th>
      <th>season</th>
      <th>holiday</th>
      <th>workingday</th>
      <th>weather</th>
      <th>temp</th>
      <th>atemp</th>
      <th>humidity</th>
      <th>windspeed</th>
      <th>casual</th>
      <th>registered</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011-01-01 00:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>81</td>
      <td>0.0</td>
      <td>3</td>
      <td>13</td>
      <td>16</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011-01-01 01:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0</td>
      <td>8</td>
      <td>32</td>
      <td>40</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011-01-01 02:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0</td>
      <td>5</td>
      <td>27</td>
      <td>32</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011-01-01 03:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0</td>
      <td>3</td>
      <td>10</td>
      <td>13</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011-01-01 04:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-4d02188e-d985-488e-b9ed-36d4f936a3c2')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-4d02188e-d985-488e-b9ed-36d4f936a3c2 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-4d02188e-d985-488e-b9ed-36d4f936a3c2');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell code" data-execution_count="12" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:364}" id="L1CYcT83VrG6" data-outputId="8e36af88-26d3-4ea8-ac5d-575aebb74762">
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple output of the train dataset to view some of the min/max/varition of the dataset features.</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>train.describe()</span></code></pre></div>
<div class="output execute_result" data-execution_count="12">

  <div id="df-14e49e57-76c4-47d7-88db-dfdb71466ea9">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>season</th>
      <th>holiday</th>
      <th>workingday</th>
      <th>weather</th>
      <th>temp</th>
      <th>atemp</th>
      <th>humidity</th>
      <th>windspeed</th>
      <th>casual</th>
      <th>registered</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.00000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>2.506614</td>
      <td>0.028569</td>
      <td>0.680875</td>
      <td>1.418427</td>
      <td>20.23086</td>
      <td>23.655084</td>
      <td>61.886460</td>
      <td>12.799395</td>
      <td>36.021955</td>
      <td>155.552177</td>
      <td>191.574132</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.116174</td>
      <td>0.166599</td>
      <td>0.466159</td>
      <td>0.633839</td>
      <td>7.79159</td>
      <td>8.474601</td>
      <td>19.245033</td>
      <td>8.164537</td>
      <td>49.960477</td>
      <td>151.039033</td>
      <td>181.144454</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.82000</td>
      <td>0.760000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>2.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>13.94000</td>
      <td>16.665000</td>
      <td>47.000000</td>
      <td>7.001500</td>
      <td>4.000000</td>
      <td>36.000000</td>
      <td>42.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>3.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>20.50000</td>
      <td>24.240000</td>
      <td>62.000000</td>
      <td>12.998000</td>
      <td>17.000000</td>
      <td>118.000000</td>
      <td>145.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>4.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>2.000000</td>
      <td>26.24000</td>
      <td>31.060000</td>
      <td>77.000000</td>
      <td>16.997900</td>
      <td>49.000000</td>
      <td>222.000000</td>
      <td>284.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>4.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>4.000000</td>
      <td>41.00000</td>
      <td>45.455000</td>
      <td>100.000000</td>
      <td>56.996900</td>
      <td>367.000000</td>
      <td>886.000000</td>
      <td>977.000000</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-14e49e57-76c4-47d7-88db-dfdb71466ea9')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-14e49e57-76c4-47d7-88db-dfdb71466ea9 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-14e49e57-76c4-47d7-88db-dfdb71466ea9');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell code" data-execution_count="14" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}" id="R7dE9Iy7VrG6" data-outputId="8415018e-c106-4c8d-f9e8-d4134bf0930f">
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the test pandas dataframe in pandas by reading the csv, remember to parse the datetime!</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>test <span class="op">=</span> pd.read_csv(<span class="st">&#39;test.csv&#39;</span>, parse_dates<span class="op">=</span>[<span class="st">&quot;datetime&quot;</span>])</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>test.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="14">

  <div id="df-b8e0a46a-460f-41df-b624-83075ce3ba3b">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>datetime</th>
      <th>season</th>
      <th>holiday</th>
      <th>workingday</th>
      <th>weather</th>
      <th>temp</th>
      <th>atemp</th>
      <th>humidity</th>
      <th>windspeed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011-01-20 00:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10.66</td>
      <td>11.365</td>
      <td>56</td>
      <td>26.0027</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011-01-20 01:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10.66</td>
      <td>13.635</td>
      <td>56</td>
      <td>0.0000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011-01-20 02:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10.66</td>
      <td>13.635</td>
      <td>56</td>
      <td>0.0000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011-01-20 03:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10.66</td>
      <td>12.880</td>
      <td>56</td>
      <td>11.0014</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011-01-20 04:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10.66</td>
      <td>12.880</td>
      <td>56</td>
      <td>11.0014</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-b8e0a46a-460f-41df-b624-83075ce3ba3b')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-b8e0a46a-460f-41df-b624-83075ce3ba3b button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-b8e0a46a-460f-41df-b624-83075ce3ba3b');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell code" data-execution_count="15" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:210}" id="b68NZyReVrG6" data-outputId="3be6f164-29f3-4af7-f418-db60de4f6d41">
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Same thing as train and test dataset</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>submission <span class="op">=</span> pd.read_csv(<span class="st">&#39;sampleSubmission.csv&#39;</span>, parse_dates<span class="op">=</span>[<span class="st">&quot;datetime&quot;</span>])</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>submission.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="15">

  <div id="df-9725661c-856b-4a19-9ace-cc7cb06d890d">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>datetime</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011-01-20 00:00:00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011-01-20 01:00:00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011-01-20 02:00:00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011-01-20 03:00:00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011-01-20 04:00:00</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-9725661c-856b-4a19-9ace-cc7cb06d890d')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-9725661c-856b-4a19-9ace-cc7cb06d890d button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-9725661c-856b-4a19-9ace-cc7cb06d890d');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<section id="step-3-train-a-model-using-autogluons-tabular-prediction" class="cell markdown" id="Io9fRTMOVrG6">
<h2>Step 3: Train a model using AutoGluon’s Tabular Prediction</h2>
</section>
<div class="cell markdown" id="s6KBTJWEVrG7">
<p>Requirements:</p>
<ul>
<li>We are prediting <code>count</code>, so it is the label we are setting.</li>
<li>Ignore <code>casual</code> and <code>registered</code> columns as they are also not present in the test dataset.</li>
<li>Use the <code>root_mean_squared_error</code> as the metric to use for evaluation.</li>
<li>Set a time limit of 10 minutes (600 seconds).</li>
<li>Use the preset <code>best_quality</code> to focus on creating the best model.</li>
</ul>
</div>
<div class="cell code" data-execution_count="21" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="XkZZXzwMVrG7" data-outputId="6d178d33-9480-4b1f-9486-a29a34996c1a">
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>predictor <span class="op">=</span> TabularPredictor(label<span class="op">=</span><span class="st">&quot;count&quot;</span>, problem_type<span class="op">=</span><span class="st">&quot;regression&quot;</span>, eval_metric<span class="op">=</span><span class="st">&quot;root_mean_squared_error&quot;</span>).fit(train_data<span class="op">=</span>train.drop([<span class="st">&#39;casual&#39;</span>, <span class="st">&#39;registered&#39;</span>], axis<span class="op">=</span><span class="dv">1</span>), time_limit<span class="op">=</span><span class="dv">600</span>, presets<span class="op">=</span><span class="st">&quot;best_quality&quot;</span>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>No path specified. Models will be saved in: &quot;AutogluonModels/ag-20230531_202924/&quot;
Presets specified: [&#39;best_quality&#39;]
Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20
Beginning AutoGluon training ... Time limit = 600s
AutoGluon will save models to &quot;AutogluonModels/ag-20230531_202924/&quot;
AutoGluon Version:  0.7.0
Python Version:     3.10.11
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #1 SMP Sat Apr 29 09:15:28 UTC 2023
Train Data Rows:    10886
Train Data Columns: 9
Label Column: count
Preprocessing data ...
Using Feature Generators to preprocess the data ...
Fitting AutoMLPipelineFeatureGenerator...
	Available Memory:                    11113.32 MB
	Train Data (Original)  Memory Usage: 0.78 MB (0.0% of available memory)
	Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.
	Stage 1 Generators:
		Fitting AsTypeFeatureGenerator...
			Note: Converting 2 features to boolean dtype as they only contain 2 unique values.
	Stage 2 Generators:
		Fitting FillNaFeatureGenerator...
	Stage 3 Generators:
		Fitting IdentityFeatureGenerator...
		Fitting DatetimeFeatureGenerator...
	Stage 4 Generators:
		Fitting DropUniqueFeatureGenerator...
	Types of features in original data (raw dtype, special dtypes):
		(&#39;datetime&#39;, []) : 1 | [&#39;datetime&#39;]
		(&#39;float&#39;, [])    : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])      : 5 | [&#39;season&#39;, &#39;holiday&#39;, &#39;workingday&#39;, &#39;weather&#39;, &#39;humidity&#39;]
	Types of features in processed data (raw dtype, special dtypes):
		(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])                  : 3 | [&#39;season&#39;, &#39;weather&#39;, &#39;humidity&#39;]
		(&#39;int&#39;, [&#39;bool&#39;])            : 2 | [&#39;holiday&#39;, &#39;workingday&#39;]
		(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
	0.3s = Fit runtime
	9 features in original data used to generate 13 features in processed data.
	Train Data (Processed) Memory Usage: 0.98 MB (0.0% of available memory)
Data preprocessing and feature engineering runtime = 0.36s ...
AutoGluon will gauge predictive performance using evaluation metric: &#39;root_mean_squared_error&#39;
	This metric&#39;s sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	To change this, specify the eval_metric parameter of Predictor()
AutoGluon will fit 2 stack levels (L1 to L2) ...
Fitting 11 L1 models ...
Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 399.66s of the 599.63s of remaining time.
	-101.5462	 = Validation score   (-root_mean_squared_error)
	0.13s	 = Training   runtime
	0.12s	 = Validation runtime
Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 399.33s of the 599.3s of remaining time.
	-84.1251	 = Validation score   (-root_mean_squared_error)
	0.15s	 = Training   runtime
	0.14s	 = Validation runtime
Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 398.97s of the 598.94s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-131.4609	 = Validation score   (-root_mean_squared_error)
	91.1s	 = Training   runtime
	15.02s	 = Validation runtime
Fitting model: LightGBM_BAG_L1 ... Training model for up to 300.01s of the 499.98s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-131.0542	 = Validation score   (-root_mean_squared_error)
	41.93s	 = Training   runtime
	2.61s	 = Validation runtime
Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 253.48s of the 453.45s of remaining time.
	-116.5484	 = Validation score   (-root_mean_squared_error)
	15.12s	 = Training   runtime
	0.78s	 = Validation runtime
Fitting model: CatBoost_BAG_L1 ... Training model for up to 236.27s of the 436.24s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-130.6532	 = Validation score   (-root_mean_squared_error)
	192.66s	 = Training   runtime
	0.15s	 = Validation runtime
Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 37.25s of the 237.23s of remaining time.
	-124.6007	 = Validation score   (-root_mean_squared_error)
	5.67s	 = Training   runtime
	0.55s	 = Validation runtime
Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 30.06s of the 230.03s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-141.8325	 = Validation score   (-root_mean_squared_error)
	59.88s	 = Training   runtime
	0.4s	 = Validation runtime
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 164.46s of remaining time.
	-84.1251	 = Validation score   (-root_mean_squared_error)
	0.67s	 = Training   runtime
	0.0s	 = Validation runtime
Fitting 9 L2 models ...
Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 163.76s of the 163.74s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-60.2738	 = Validation score   (-root_mean_squared_error)
	74.59s	 = Training   runtime
	7.12s	 = Validation runtime
Fitting model: LightGBM_BAG_L2 ... Training model for up to 82.29s of the 82.27s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-54.9975	 = Validation score   (-root_mean_squared_error)
	33.54s	 = Training   runtime
	0.49s	 = Validation runtime
Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 41.46s of the 41.45s of remaining time.
	-53.2207	 = Validation score   (-root_mean_squared_error)
	44.21s	 = Training   runtime
	0.65s	 = Validation runtime
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -4.11s of remaining time.
	-52.943	 = Validation score   (-root_mean_squared_error)
	0.23s	 = Training   runtime
	0.0s	 = Validation runtime
AutoGluon training complete, total runtime = 604.39s ... Best model: &quot;WeightedEnsemble_L3&quot;
TabularPredictor saved. To load, use: predictor = TabularPredictor.load(&quot;AutogluonModels/ag-20230531_202924/&quot;)
</code></pre>
</div>
</div>
<section id="review-autogluons-training-run-with-ranking-of-models-that-did-the-best" class="cell markdown" id="6ZgdapEMVrG7">
<h3>Review AutoGluon's training run with ranking of models that did the best.</h3>
</section>
<div class="cell code" data-execution_count="22" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="PTgvTqIjVrG7" data-outputId="e3ab082f-7def-4017-9c95-b2c366736cb6">
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>predictor.fit_summary()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>*** Summary of fit() ***
Estimated performance of each model:
                     model   score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order
0      WeightedEnsemble_L3  -52.942981      28.012615  559.202208                0.000794           0.227751            3       True         13
1   RandomForestMSE_BAG_L2  -53.220711      20.409040  450.844197                0.645022          44.208113            2       True         12
2          LightGBM_BAG_L2  -54.997493      20.249145  440.177261                0.485127          33.541177            2       True         11
3        LightGBMXT_BAG_L2  -60.273818      26.881672  481.225167                7.117654          74.589083            2       True         10
4    KNeighborsDist_BAG_L1  -84.125061       0.136697    0.150902                0.136697           0.150902            1       True          2
5      WeightedEnsemble_L2  -84.125061       0.137683    0.818151                0.000986           0.667248            2       True          9
6    KNeighborsUnif_BAG_L1 -101.546199       0.123503    0.125026                0.123503           0.125026            1       True          1
7   RandomForestMSE_BAG_L1 -116.548359       0.781808   15.121769                0.781808          15.121769            1       True          5
8     ExtraTreesMSE_BAG_L1 -124.600676       0.546782    5.665171                0.546782           5.665171            1       True          7
9          CatBoost_BAG_L1 -130.653155       0.149575  192.662432                0.149575         192.662432            1       True          6
10         LightGBM_BAG_L1 -131.054162       2.607525   41.931610                2.607525          41.931610            1       True          4
11       LightGBMXT_BAG_L1 -131.460909      15.022099   91.096239               15.022099          91.096239            1       True          3
12  NeuralNetFastAI_BAG_L1 -141.832519       0.396029   59.882936                0.396029          59.882936            1       True          8
Number of models trained: 13
Types of models trained:
{&#39;StackerEnsembleModel_LGB&#39;, &#39;StackerEnsembleModel_XT&#39;, &#39;StackerEnsembleModel_CatBoost&#39;, &#39;StackerEnsembleModel_RF&#39;, &#39;StackerEnsembleModel_NNFastAiTabular&#39;, &#39;StackerEnsembleModel_KNN&#39;, &#39;WeightedEnsembleModel&#39;}
Bagging used: True  (with 8 folds)
Multi-layer stack-ensembling used: True  (with 3 levels)
Feature Metadata (Processed):
(raw dtype, special dtypes):
(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
(&#39;int&#39;, [])                  : 3 | [&#39;season&#39;, &#39;weather&#39;, &#39;humidity&#39;]
(&#39;int&#39;, [&#39;bool&#39;])            : 2 | [&#39;holiday&#39;, &#39;workingday&#39;]
(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
*** End of fit() summary ***
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.10/dist-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;
  warnings.warn(&#39;AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;&#39;)
</code></pre>
</div>
<div class="output execute_result" data-execution_count="22">
<pre><code>{&#39;model_types&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: &#39;StackerEnsembleModel_KNN&#39;,
  &#39;KNeighborsDist_BAG_L1&#39;: &#39;StackerEnsembleModel_KNN&#39;,
  &#39;LightGBMXT_BAG_L1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;RandomForestMSE_BAG_L1&#39;: &#39;StackerEnsembleModel_RF&#39;,
  &#39;CatBoost_BAG_L1&#39;: &#39;StackerEnsembleModel_CatBoost&#39;,
  &#39;ExtraTreesMSE_BAG_L1&#39;: &#39;StackerEnsembleModel_XT&#39;,
  &#39;NeuralNetFastAI_BAG_L1&#39;: &#39;StackerEnsembleModel_NNFastAiTabular&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;WeightedEnsembleModel&#39;,
  &#39;LightGBMXT_BAG_L2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;RandomForestMSE_BAG_L2&#39;: &#39;StackerEnsembleModel_RF&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;WeightedEnsembleModel&#39;},
 &#39;model_performance&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: -101.54619908446061,
  &#39;KNeighborsDist_BAG_L1&#39;: -84.12506123181602,
  &#39;LightGBMXT_BAG_L1&#39;: -131.46090891834504,
  &#39;LightGBM_BAG_L1&#39;: -131.054161598899,
  &#39;RandomForestMSE_BAG_L1&#39;: -116.54835939455667,
  &#39;CatBoost_BAG_L1&#39;: -130.65315499245077,
  &#39;ExtraTreesMSE_BAG_L1&#39;: -124.60067564699747,
  &#39;NeuralNetFastAI_BAG_L1&#39;: -141.83251908476262,
  &#39;WeightedEnsemble_L2&#39;: -84.12506123181602,
  &#39;LightGBMXT_BAG_L2&#39;: -60.27381816801946,
  &#39;LightGBM_BAG_L2&#39;: -54.99749270816186,
  &#39;RandomForestMSE_BAG_L2&#39;: -53.220711048746395,
  &#39;WeightedEnsemble_L3&#39;: -52.942981469529094},
 &#39;model_best&#39;: &#39;WeightedEnsemble_L3&#39;,
 &#39;model_paths&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: &#39;AutogluonModels/ag-20230531_202924/models/KNeighborsUnif_BAG_L1/&#39;,
  &#39;KNeighborsDist_BAG_L1&#39;: &#39;AutogluonModels/ag-20230531_202924/models/KNeighborsDist_BAG_L1/&#39;,
  &#39;LightGBMXT_BAG_L1&#39;: &#39;AutogluonModels/ag-20230531_202924/models/LightGBMXT_BAG_L1/&#39;,
  &#39;LightGBM_BAG_L1&#39;: &#39;AutogluonModels/ag-20230531_202924/models/LightGBM_BAG_L1/&#39;,
  &#39;RandomForestMSE_BAG_L1&#39;: &#39;AutogluonModels/ag-20230531_202924/models/RandomForestMSE_BAG_L1/&#39;,
  &#39;CatBoost_BAG_L1&#39;: &#39;AutogluonModels/ag-20230531_202924/models/CatBoost_BAG_L1/&#39;,
  &#39;ExtraTreesMSE_BAG_L1&#39;: &#39;AutogluonModels/ag-20230531_202924/models/ExtraTreesMSE_BAG_L1/&#39;,
  &#39;NeuralNetFastAI_BAG_L1&#39;: &#39;AutogluonModels/ag-20230531_202924/models/NeuralNetFastAI_BAG_L1/&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;AutogluonModels/ag-20230531_202924/models/WeightedEnsemble_L2/&#39;,
  &#39;LightGBMXT_BAG_L2&#39;: &#39;AutogluonModels/ag-20230531_202924/models/LightGBMXT_BAG_L2/&#39;,
  &#39;LightGBM_BAG_L2&#39;: &#39;AutogluonModels/ag-20230531_202924/models/LightGBM_BAG_L2/&#39;,
  &#39;RandomForestMSE_BAG_L2&#39;: &#39;AutogluonModels/ag-20230531_202924/models/RandomForestMSE_BAG_L2/&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;AutogluonModels/ag-20230531_202924/models/WeightedEnsemble_L3/&#39;},
 &#39;model_fit_times&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: 0.12502551078796387,
  &#39;KNeighborsDist_BAG_L1&#39;: 0.15090227127075195,
  &#39;LightGBMXT_BAG_L1&#39;: 91.09623861312866,
  &#39;LightGBM_BAG_L1&#39;: 41.931610345840454,
  &#39;RandomForestMSE_BAG_L1&#39;: 15.121768712997437,
  &#39;CatBoost_BAG_L1&#39;: 192.66243195533752,
  &#39;ExtraTreesMSE_BAG_L1&#39;: 5.665170669555664,
  &#39;NeuralNetFastAI_BAG_L1&#39;: 59.882936000823975,
  &#39;WeightedEnsemble_L2&#39;: 0.6672484874725342,
  &#39;LightGBMXT_BAG_L2&#39;: 74.58908271789551,
  &#39;LightGBM_BAG_L2&#39;: 33.54117727279663,
  &#39;RandomForestMSE_BAG_L2&#39;: 44.208112716674805,
  &#39;WeightedEnsemble_L3&#39;: 0.2277512550354004},
 &#39;model_pred_times&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: 0.12350320816040039,
  &#39;KNeighborsDist_BAG_L1&#39;: 0.13669681549072266,
  &#39;LightGBMXT_BAG_L1&#39;: 15.022098541259766,
  &#39;LightGBM_BAG_L1&#39;: 2.60752534866333,
  &#39;RandomForestMSE_BAG_L1&#39;: 0.7818078994750977,
  &#39;CatBoost_BAG_L1&#39;: 0.14957523345947266,
  &#39;ExtraTreesMSE_BAG_L1&#39;: 0.5467824935913086,
  &#39;NeuralNetFastAI_BAG_L1&#39;: 0.3960285186767578,
  &#39;WeightedEnsemble_L2&#39;: 0.000986337661743164,
  &#39;LightGBMXT_BAG_L2&#39;: 7.1176536083221436,
  &#39;LightGBM_BAG_L2&#39;: 0.48512721061706543,
  &#39;RandomForestMSE_BAG_L2&#39;: 0.6450223922729492,
  &#39;WeightedEnsemble_L3&#39;: 0.0007939338684082031},
 &#39;num_bag_folds&#39;: 8,
 &#39;max_stack_level&#39;: 3,
 &#39;model_hyperparams&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;KNeighborsDist_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;LightGBMXT_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;RandomForestMSE_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;CatBoost_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;ExtraTreesMSE_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;NeuralNetFastAI_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L2&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBMXT_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;RandomForestMSE_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;WeightedEnsemble_L3&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True}},
 &#39;leaderboard&#39;:                      model   score_val  pred_time_val    fit_time  \
 0      WeightedEnsemble_L3  -52.942981      28.012615  559.202208   
 1   RandomForestMSE_BAG_L2  -53.220711      20.409040  450.844197   
 2          LightGBM_BAG_L2  -54.997493      20.249145  440.177261   
 3        LightGBMXT_BAG_L2  -60.273818      26.881672  481.225167   
 4    KNeighborsDist_BAG_L1  -84.125061       0.136697    0.150902   
 5      WeightedEnsemble_L2  -84.125061       0.137683    0.818151   
 6    KNeighborsUnif_BAG_L1 -101.546199       0.123503    0.125026   
 7   RandomForestMSE_BAG_L1 -116.548359       0.781808   15.121769   
 8     ExtraTreesMSE_BAG_L1 -124.600676       0.546782    5.665171   
 9          CatBoost_BAG_L1 -130.653155       0.149575  192.662432   
 10         LightGBM_BAG_L1 -131.054162       2.607525   41.931610   
 11       LightGBMXT_BAG_L1 -131.460909      15.022099   91.096239   
 12  NeuralNetFastAI_BAG_L1 -141.832519       0.396029   59.882936   
 
     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \
 0                 0.000794           0.227751            3       True   
 1                 0.645022          44.208113            2       True   
 2                 0.485127          33.541177            2       True   
 3                 7.117654          74.589083            2       True   
 4                 0.136697           0.150902            1       True   
 5                 0.000986           0.667248            2       True   
 6                 0.123503           0.125026            1       True   
 7                 0.781808          15.121769            1       True   
 8                 0.546782           5.665171            1       True   
 9                 0.149575         192.662432            1       True   
 10                2.607525          41.931610            1       True   
 11               15.022099          91.096239            1       True   
 12                0.396029          59.882936            1       True   
 
     fit_order  
 0          13  
 1          12  
 2          11  
 3          10  
 4           2  
 5           9  
 6           1  
 7           5  
 8           7  
 9           6  
 10          4  
 11          3  
 12          8  }</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="64" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:648}" id="338q4uDDvsNU" data-outputId="accca66b-d6b7-43c4-d09a-ff30279244ca">
<div class="sourceCode" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>predictor.leaderboard(silent<span class="op">=</span><span class="va">True</span>).plot(kind<span class="op">=</span><span class="st">&quot;bar&quot;</span>, x<span class="op">=</span><span class="st">&quot;model&quot;</span>, y<span class="op">=</span><span class="st">&quot;score_val&quot;</span>)</span></code></pre></div>
<div class="output execute_result" data-execution_count="64">
<pre><code>&lt;Axes: xlabel=&#39;model&#39;&gt;</code></pre>
</div>
<div class="output display_data">
<p><img src="c4d2ace0e7a24ad6319446d7df9a08258692df19.png" /></p>
</div>
</div>
<section id="create-predictions-from-test-dataset" class="cell markdown" id="PKZzByp7VrG7">
<h3>Create predictions from test dataset</h3>
</section>
<div class="cell code" data-execution_count="27" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}" id="ZWG4vSyUVrG8" data-outputId="ca4b68cd-eba5-4dab-93f1-b99bafab4a88">
<div class="sourceCode" id="cb20"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> pd.DataFrame({<span class="st">&#39;datetime&#39;</span>:test[<span class="st">&#39;datetime&#39;</span>], <span class="st">&#39;count&#39;</span>:predictor.predict(test)})</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>predictions.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="27">

  <div id="df-0c1a4aaa-410c-4d81-81e0-4d4ca4ee30e4">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>datetime</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011-01-20 00:00:00</td>
      <td>22.300045</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011-01-20 01:00:00</td>
      <td>42.226509</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011-01-20 02:00:00</td>
      <td>46.095669</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011-01-20 03:00:00</td>
      <td>48.929375</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011-01-20 04:00:00</td>
      <td>51.722336</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-0c1a4aaa-410c-4d81-81e0-4d4ca4ee30e4')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-0c1a4aaa-410c-4d81-81e0-4d4ca4ee30e4 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-0c1a4aaa-410c-4d81-81e0-4d4ca4ee30e4');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<section id="note-kaggle-will-reject-the-submission-if-we-dont-set-everything-to-be--0" class="cell markdown" id="YpK6M0uRVrG8">
<h4>NOTE: Kaggle will reject the submission if we don't set everything to be &gt; 0.</h4>
</section>
<div class="cell code" data-execution_count="28" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:300}" id="DqbxWTILVrG8" data-outputId="309c44fb-45a6-4377-855c-f22d57057f42">
<div class="sourceCode" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Describe the `predictions` series to see if there are any negative values</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>predictions.describe()</span></code></pre></div>
<div class="output execute_result" data-execution_count="28">

  <div id="df-6c28b01c-504c-4cd6-9bc1-6f1796047b98">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>6493.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>100.526901</td>
    </tr>
    <tr>
      <th>std</th>
      <td>89.845695</td>
    </tr>
    <tr>
      <th>min</th>
      <td>2.864271</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>20.236641</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>63.113747</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>167.290939</td>
    </tr>
    <tr>
      <th>max</th>
      <td>366.549835</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-6c28b01c-504c-4cd6-9bc1-6f1796047b98')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-6c28b01c-504c-4cd6-9bc1-6f1796047b98 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-6c28b01c-504c-4cd6-9bc1-6f1796047b98');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell code" data-execution_count="45" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="2zSVmfaoVrG8" data-outputId="fa65a41b-c653-4ca0-f920-20acdf22c3f8">
<div class="sourceCode" id="cb22"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># How many negative values do we have?</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>predictions[(predictions[<span class="st">&#39;count&#39;</span>] <span class="op">&lt;</span> <span class="dv">0</span>)].<span class="bu">sum</span>(numeric_only<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
<div class="output execute_result" data-execution_count="45">
<pre><code>count    0.0
dtype: float64</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="46" id="oPBrQxTfVrG8">
<div class="sourceCode" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set them to zero</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>predictions[(predictions[<span class="st">&#39;count&#39;</span>] <span class="op">&lt;</span> <span class="dv">0</span>)] <span class="op">=</span> <span class="dv">0</span></span></code></pre></div>
</div>
<section id="set-predictions-to-submission-dataframe-save-and-submit" class="cell markdown" id="9_PMKlNDVrG8">
<h3>Set predictions to submission dataframe, save, and submit</h3>
</section>
<div class="cell code" data-execution_count="47" id="0yUjifxJVrG8">
<div class="sourceCode" id="cb25"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>submission[<span class="st">&quot;count&quot;</span>] <span class="op">=</span> predictions[<span class="st">&#39;count&#39;</span>]</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>submission.to_csv(<span class="st">&quot;submission.csv&quot;</span>, index<span class="op">=</span><span class="va">False</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="48" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="stPdmR-fVrG8" data-outputId="025f23ef-5df3-4362-dd65-33e235544197">
<div class="sourceCode" id="cb26"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submit <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">-</span>f submission.csv <span class="op">-</span>m <span class="st">&quot;first raw submission&quot;</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>100% 188k/188k [00:03&lt;00:00, 62.3kB/s]
Successfully submitted to Bike Sharing Demand</code></pre>
</div>
</div>
<section id="view-submission-via-the-command-line-or-in-the-web-browser-under-the-competitions-page---my-submissions" class="cell markdown" id="AzXWquvdVrG9">
<h4>View submission via the command line or in the web browser under the competition's page - <code>My Submissions</code></h4>
</section>
<div class="cell code" data-execution_count="49" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="Fyy2JzzjVrG9" data-outputId="b951bc7d-5667-4afb-a278-00655a869378">
<div class="sourceCode" id="cb28"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submissions <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">|</span> tail <span class="op">-</span>n <span class="op">+</span><span class="dv">1</span> <span class="op">|</span> head <span class="op">-</span>n <span class="dv">6</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>fileName        date                 description           status    publicScore  privateScore  
--------------  -------------------  --------------------  --------  -----------  ------------  
submission.csv  2023-05-31 21:01:25  first raw submission  complete  1.80169      1.80169       
</code></pre>
</div>
</div>
<section id="initial-score-of-180169" class="cell markdown" id="CsAAxDLBVrG9">
<h4>Initial score of <code>1.80169</code></h4>
</section>
<section id="step-4-exploratory-data-analysis-and-creating-an-additional-feature" class="cell markdown" id="w5yOE4E1VrG9">
<h2>Step 4: Exploratory Data Analysis and Creating an additional feature</h2>
<ul>
<li>Any additional feature will do, but a great suggestion would be to separate out the datetime into hour, day, or month parts.</li>
</ul>
</section>
<div class="cell code" data-execution_count="50" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:660}" id="Hh2Y6NxLVrHB" data-outputId="0ac23544-86b3-48e5-a180-1512047abeb0">
<div class="sourceCode" id="cb30"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a histogram of all features to show the distribution of each one relative to the data. This is part of the exploritory data analysis</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>train.hist()</span></code></pre></div>
<div class="output execute_result" data-execution_count="50">
<pre><code>array([[&lt;Axes: title={&#39;center&#39;: &#39;datetime&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;season&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;holiday&#39;}&gt;],
       [&lt;Axes: title={&#39;center&#39;: &#39;workingday&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;weather&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;temp&#39;}&gt;],
       [&lt;Axes: title={&#39;center&#39;: &#39;atemp&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;humidity&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;windspeed&#39;}&gt;],
       [&lt;Axes: title={&#39;center&#39;: &#39;casual&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;registered&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;count&#39;}&gt;]], dtype=object)</code></pre>
</div>
<div class="output display_data">
<p><img src="b6eaaf5f61b3db11b62789e9cc4a53d3d83d482e.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="52" id="8ptU6WWqVrHB">
<div class="sourceCode" id="cb32"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create a new feature</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&#39;year&#39;</span>] <span class="op">=</span> train[<span class="st">&#39;datetime&#39;</span>].dt.year</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&#39;year&#39;</span>] <span class="op">=</span> test[<span class="st">&#39;datetime&#39;</span>].dt.year</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&#39;month&#39;</span>] <span class="op">=</span> train[<span class="st">&#39;datetime&#39;</span>].dt.month</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&#39;month&#39;</span>] <span class="op">=</span> test[<span class="st">&#39;datetime&#39;</span>].dt.month</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&#39;day&#39;</span>] <span class="op">=</span> train[<span class="st">&#39;datetime&#39;</span>].dt.day</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&#39;day&#39;</span>] <span class="op">=</span> test[<span class="st">&#39;datetime&#39;</span>].dt.day</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&#39;hour&#39;</span>] <span class="op">=</span> train[<span class="st">&#39;datetime&#39;</span>].dt.hour</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&#39;hour&#39;</span>] <span class="op">=</span> test[<span class="st">&#39;datetime&#39;</span>].dt.hour</span></code></pre></div>
</div>
<section id="make-category-types-for-these-so-models-know-they-are-not-just-numbers" class="cell markdown" id="MG5SZhCuVrHC">
<h2>Make category types for these so models know they are not just numbers</h2>
<ul>
<li>AutoGluon originally sees these as ints, but in reality they are int representations of a category.</li>
<li>Setting the dtype to category will classify these as categories in AutoGluon.</li>
</ul>
</section>
<div class="cell code" data-execution_count="53" id="9U_ZGocdVrHC">
<div class="sourceCode" id="cb33"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&quot;season&quot;</span>] <span class="op">=</span> train[<span class="st">&quot;season&quot;</span>].astype(<span class="st">&quot;category&quot;</span>)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&quot;weather&quot;</span>] <span class="op">=</span> train[<span class="st">&quot;weather&quot;</span>].astype(<span class="st">&quot;category&quot;</span>)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&quot;season&quot;</span>] <span class="op">=</span> test[<span class="st">&quot;season&quot;</span>].astype(<span class="st">&quot;category&quot;</span>)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&quot;weather&quot;</span>] <span class="op">=</span> test[<span class="st">&quot;weather&quot;</span>].astype(<span class="st">&quot;category&quot;</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="54" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:443}" id="uZ85c6ESVrHC" data-outputId="75f2684c-6123-4be0-dfb6-57e05229b4c4">
<div class="sourceCode" id="cb34"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># View are new feature</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>train.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="54">

  <div id="df-c79309b6-2421-4154-8191-bb76536a35e3">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>datetime</th>
      <th>season</th>
      <th>holiday</th>
      <th>workingday</th>
      <th>weather</th>
      <th>temp</th>
      <th>atemp</th>
      <th>humidity</th>
      <th>windspeed</th>
      <th>casual</th>
      <th>registered</th>
      <th>count</th>
      <th>year</th>
      <th>month</th>
      <th>day</th>
      <th>hour</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011-01-01 00:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>81</td>
      <td>0.0</td>
      <td>3</td>
      <td>13</td>
      <td>16</td>
      <td>2011</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011-01-01 01:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0</td>
      <td>8</td>
      <td>32</td>
      <td>40</td>
      <td>2011</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011-01-01 02:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0</td>
      <td>5</td>
      <td>27</td>
      <td>32</td>
      <td>2011</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011-01-01 03:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0</td>
      <td>3</td>
      <td>10</td>
      <td>13</td>
      <td>2011</td>
      <td>1</td>
      <td>1</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011-01-01 04:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>2011</td>
      <td>1</td>
      <td>1</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-c79309b6-2421-4154-8191-bb76536a35e3')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-c79309b6-2421-4154-8191-bb76536a35e3 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-c79309b6-2421-4154-8191-bb76536a35e3');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell code" data-execution_count="55" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:712}" id="u52GXEWhVrHC" data-outputId="b262d299-07ab-447e-e1d6-f98eab712552">
<div class="sourceCode" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># View histogram of all features again now with the hour feature</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>train.hist()</span></code></pre></div>
<div class="output execute_result" data-execution_count="55">
<pre><code>array([[&lt;Axes: title={&#39;center&#39;: &#39;datetime&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;holiday&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;workingday&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;temp&#39;}&gt;],
       [&lt;Axes: title={&#39;center&#39;: &#39;atemp&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;humidity&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;windspeed&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;casual&#39;}&gt;],
       [&lt;Axes: title={&#39;center&#39;: &#39;registered&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;count&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;year&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;month&#39;}&gt;],
       [&lt;Axes: title={&#39;center&#39;: &#39;day&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;hour&#39;}&gt;, &lt;Axes: &gt;, &lt;Axes: &gt;]],
      dtype=object)</code></pre>
</div>
<div class="output display_data">
<p><img src="320e638762d171f8345af2349f03bc55b5a199ca.png" /></p>
</div>
</div>
<section id="step-5-rerun-the-model-with-the-same-settings-as-before-just-with-more-features" class="cell markdown" id="9PboG549VrHC">
<h2>Step 5: Rerun the model with the same settings as before, just with more features</h2>
</section>
<div class="cell code" data-execution_count="56" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="4U67SUAVVrHD" data-outputId="c598c8ba-de42-4f07-dbdc-2bf35cbf767a">
<div class="sourceCode" id="cb37"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>predictor_new_features <span class="op">=</span> TabularPredictor(label<span class="op">=</span><span class="st">&quot;count&quot;</span>, problem_type<span class="op">=</span><span class="st">&quot;regression&quot;</span>, eval_metric<span class="op">=</span><span class="st">&quot;root_mean_squared_error&quot;</span>).fit(train_data<span class="op">=</span>train.drop([<span class="st">&#39;casual&#39;</span>, <span class="st">&#39;registered&#39;</span>], axis<span class="op">=</span><span class="dv">1</span>), time_limit<span class="op">=</span><span class="dv">600</span>, presets<span class="op">=</span><span class="st">&quot;best_quality&quot;</span>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>No path specified. Models will be saved in: &quot;AutogluonModels/ag-20230531_211121/&quot;
Presets specified: [&#39;best_quality&#39;]
Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20
Beginning AutoGluon training ... Time limit = 600s
AutoGluon will save models to &quot;AutogluonModels/ag-20230531_211121/&quot;
AutoGluon Version:  0.7.0
Python Version:     3.10.11
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #1 SMP Sat Apr 29 09:15:28 UTC 2023
Train Data Rows:    10886
Train Data Columns: 13
Label Column: count
Preprocessing data ...
Using Feature Generators to preprocess the data ...
Fitting AutoMLPipelineFeatureGenerator...
	Available Memory:                    10587.79 MB
	Train Data (Original)  Memory Usage: 0.98 MB (0.0% of available memory)
	Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.
	Stage 1 Generators:
		Fitting AsTypeFeatureGenerator...
			Note: Converting 3 features to boolean dtype as they only contain 2 unique values.
	Stage 2 Generators:
		Fitting FillNaFeatureGenerator...
	Stage 3 Generators:
		Fitting IdentityFeatureGenerator...
		Fitting CategoryFeatureGenerator...
			Fitting CategoryMemoryMinimizeFeatureGenerator...
		Fitting DatetimeFeatureGenerator...
	Stage 4 Generators:
		Fitting DropUniqueFeatureGenerator...
	Types of features in original data (raw dtype, special dtypes):
		(&#39;category&#39;, []) : 2 | [&#39;season&#39;, &#39;weather&#39;]
		(&#39;datetime&#39;, []) : 1 | [&#39;datetime&#39;]
		(&#39;float&#39;, [])    : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])      : 7 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;humidity&#39;, &#39;year&#39;, &#39;month&#39;, ...]
	Types of features in processed data (raw dtype, special dtypes):
		(&#39;category&#39;, [])             : 2 | [&#39;season&#39;, &#39;weather&#39;]
		(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])                  : 4 | [&#39;humidity&#39;, &#39;month&#39;, &#39;day&#39;, &#39;hour&#39;]
		(&#39;int&#39;, [&#39;bool&#39;])            : 3 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;year&#39;]
		(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
	0.1s = Fit runtime
	13 features in original data used to generate 17 features in processed data.
	Train Data (Processed) Memory Usage: 1.1 MB (0.0% of available memory)
Data preprocessing and feature engineering runtime = 0.19s ...
AutoGluon will gauge predictive performance using evaluation metric: &#39;root_mean_squared_error&#39;
	This metric&#39;s sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	To change this, specify the eval_metric parameter of Predictor()
AutoGluon will fit 2 stack levels (L1 to L2) ...
Fitting 11 L1 models ...
Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 399.77s of the 599.81s of remaining time.
	-101.5462	 = Validation score   (-root_mean_squared_error)
	0.04s	 = Training   runtime
	0.05s	 = Validation runtime
Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 399.64s of the 599.67s of remaining time.
	-84.1251	 = Validation score   (-root_mean_squared_error)
	0.04s	 = Training   runtime
	0.05s	 = Validation runtime
Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 399.51s of the 599.54s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-34.346	 = Validation score   (-root_mean_squared_error)
	138.24s	 = Training   runtime
	25.57s	 = Validation runtime
Fitting model: LightGBM_BAG_L1 ... Training model for up to 253.81s of the 453.85s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-33.9173	 = Validation score   (-root_mean_squared_error)
	62.06s	 = Training   runtime
	5.91s	 = Validation runtime
Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 186.24s of the 386.27s of remaining time.
	-38.3061	 = Validation score   (-root_mean_squared_error)
	23.72s	 = Training   runtime
	0.85s	 = Validation runtime
Fitting model: CatBoost_BAG_L1 ... Training model for up to 160.56s of the 360.59s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-35.2121	 = Validation score   (-root_mean_squared_error)
	150.33s	 = Training   runtime
	0.42s	 = Validation runtime
Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 6.32s of the 206.35s of remaining time.
	-38.3116	 = Validation score   (-root_mean_squared_error)
	13.63s	 = Training   runtime
	0.66s	 = Validation runtime
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 191.03s of remaining time.
	-32.2478	 = Validation score   (-root_mean_squared_error)
	0.39s	 = Training   runtime
	0.0s	 = Validation runtime
Fitting 9 L2 models ...
Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 190.61s of the 190.59s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-31.1926	 = Validation score   (-root_mean_squared_error)
	45.54s	 = Training   runtime
	1.67s	 = Validation runtime
Fitting model: LightGBM_BAG_L2 ... Training model for up to 140.8s of the 140.78s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-30.6293	 = Validation score   (-root_mean_squared_error)
	40.9s	 = Training   runtime
	0.71s	 = Validation runtime
Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 95.42s of the 95.41s of remaining time.
	-31.636	 = Validation score   (-root_mean_squared_error)
	52.73s	 = Training   runtime
	0.69s	 = Validation runtime
Fitting model: CatBoost_BAG_L2 ... Training model for up to 40.75s of the 40.74s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-31.0358	 = Validation score   (-root_mean_squared_error)
	51.39s	 = Training   runtime
	0.18s	 = Validation runtime
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -15.55s of remaining time.
	-30.3463	 = Validation score   (-root_mean_squared_error)
	0.5s	 = Training   runtime
	0.0s	 = Validation runtime
AutoGluon training complete, total runtime = 616.11s ... Best model: &quot;WeightedEnsemble_L3&quot;
TabularPredictor saved. To load, use: predictor = TabularPredictor.load(&quot;AutogluonModels/ag-20230531_211121/&quot;)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="57" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="M2E82WfsVrHD" data-outputId="676e42f0-05fc-4364-9ec4-cb0115bc3e7e">
<div class="sourceCode" id="cb39"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>predictor_new_features.fit_summary()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>*** Summary of fit() ***
Estimated performance of each model:
                     model   score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order
0      WeightedEnsemble_L3  -30.346324      36.777124  579.127208                0.002358           0.500641            3       True         13
1          LightGBM_BAG_L2  -30.629272      34.236158  428.961059                0.712554          40.902047            2       True         10
2          CatBoost_BAG_L2  -31.035759      33.705746  439.450681                0.182142          51.391669            2       True         12
3        LightGBMXT_BAG_L2  -31.192608      35.193888  433.601860                1.670284          45.542848            2       True          9
4   RandomForestMSE_BAG_L2  -31.635988      34.209787  440.790002                0.686183          52.730990            2       True         11
5      WeightedEnsemble_L2  -32.247750      32.815619  374.779061                0.000934           0.392678            2       True          8
6          LightGBM_BAG_L1  -33.917339       5.910081   62.059183                5.910081          62.059183            1       True          4
7        LightGBMXT_BAG_L1  -34.345997      25.574940  138.239162               25.574940         138.239162            1       True          3
8          CatBoost_BAG_L1  -35.212130       0.422174  150.333112                0.422174         150.333112            1       True          6
9   RandomForestMSE_BAG_L1  -38.306120       0.852840   23.716170                0.852840          23.716170            1       True          5
10    ExtraTreesMSE_BAG_L1  -38.311570       0.659421   13.632226                0.659421          13.632226            1       True          7
11   KNeighborsDist_BAG_L1  -84.125061       0.054649    0.038754                0.054649           0.038754            1       True          2
12   KNeighborsUnif_BAG_L1 -101.546199       0.049498    0.040404                0.049498           0.040404            1       True          1
Number of models trained: 13
Types of models trained:
{&#39;StackerEnsembleModel_LGB&#39;, &#39;StackerEnsembleModel_XT&#39;, &#39;StackerEnsembleModel_CatBoost&#39;, &#39;StackerEnsembleModel_RF&#39;, &#39;StackerEnsembleModel_KNN&#39;, &#39;WeightedEnsembleModel&#39;}
Bagging used: True  (with 8 folds)
Multi-layer stack-ensembling used: True  (with 3 levels)
Feature Metadata (Processed):
(raw dtype, special dtypes):
(&#39;category&#39;, [])             : 2 | [&#39;season&#39;, &#39;weather&#39;]
(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
(&#39;int&#39;, [])                  : 4 | [&#39;humidity&#39;, &#39;month&#39;, &#39;day&#39;, &#39;hour&#39;]
(&#39;int&#39;, [&#39;bool&#39;])            : 3 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;year&#39;]
(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
*** End of fit() summary ***
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.10/dist-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;
  warnings.warn(&#39;AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;&#39;)
</code></pre>
</div>
<div class="output execute_result" data-execution_count="57">
<pre><code>{&#39;model_types&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: &#39;StackerEnsembleModel_KNN&#39;,
  &#39;KNeighborsDist_BAG_L1&#39;: &#39;StackerEnsembleModel_KNN&#39;,
  &#39;LightGBMXT_BAG_L1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;RandomForestMSE_BAG_L1&#39;: &#39;StackerEnsembleModel_RF&#39;,
  &#39;CatBoost_BAG_L1&#39;: &#39;StackerEnsembleModel_CatBoost&#39;,
  &#39;ExtraTreesMSE_BAG_L1&#39;: &#39;StackerEnsembleModel_XT&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;WeightedEnsembleModel&#39;,
  &#39;LightGBMXT_BAG_L2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;RandomForestMSE_BAG_L2&#39;: &#39;StackerEnsembleModel_RF&#39;,
  &#39;CatBoost_BAG_L2&#39;: &#39;StackerEnsembleModel_CatBoost&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;WeightedEnsembleModel&#39;},
 &#39;model_performance&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: -101.54619908446061,
  &#39;KNeighborsDist_BAG_L1&#39;: -84.12506123181602,
  &#39;LightGBMXT_BAG_L1&#39;: -34.34599701170154,
  &#39;LightGBM_BAG_L1&#39;: -33.91733862651761,
  &#39;RandomForestMSE_BAG_L1&#39;: -38.30612025079756,
  &#39;CatBoost_BAG_L1&#39;: -35.21213029178584,
  &#39;ExtraTreesMSE_BAG_L1&#39;: -38.31157013220686,
  &#39;WeightedEnsemble_L2&#39;: -32.247750304288445,
  &#39;LightGBMXT_BAG_L2&#39;: -31.19260795602087,
  &#39;LightGBM_BAG_L2&#39;: -30.62927205053392,
  &#39;RandomForestMSE_BAG_L2&#39;: -31.635987772635602,
  &#39;CatBoost_BAG_L2&#39;: -31.03575899259126,
  &#39;WeightedEnsemble_L3&#39;: -30.346323751570484},
 &#39;model_best&#39;: &#39;WeightedEnsemble_L3&#39;,
 &#39;model_paths&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: &#39;AutogluonModels/ag-20230531_211121/models/KNeighborsUnif_BAG_L1/&#39;,
  &#39;KNeighborsDist_BAG_L1&#39;: &#39;AutogluonModels/ag-20230531_211121/models/KNeighborsDist_BAG_L1/&#39;,
  &#39;LightGBMXT_BAG_L1&#39;: &#39;AutogluonModels/ag-20230531_211121/models/LightGBMXT_BAG_L1/&#39;,
  &#39;LightGBM_BAG_L1&#39;: &#39;AutogluonModels/ag-20230531_211121/models/LightGBM_BAG_L1/&#39;,
  &#39;RandomForestMSE_BAG_L1&#39;: &#39;AutogluonModels/ag-20230531_211121/models/RandomForestMSE_BAG_L1/&#39;,
  &#39;CatBoost_BAG_L1&#39;: &#39;AutogluonModels/ag-20230531_211121/models/CatBoost_BAG_L1/&#39;,
  &#39;ExtraTreesMSE_BAG_L1&#39;: &#39;AutogluonModels/ag-20230531_211121/models/ExtraTreesMSE_BAG_L1/&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;AutogluonModels/ag-20230531_211121/models/WeightedEnsemble_L2/&#39;,
  &#39;LightGBMXT_BAG_L2&#39;: &#39;AutogluonModels/ag-20230531_211121/models/LightGBMXT_BAG_L2/&#39;,
  &#39;LightGBM_BAG_L2&#39;: &#39;AutogluonModels/ag-20230531_211121/models/LightGBM_BAG_L2/&#39;,
  &#39;RandomForestMSE_BAG_L2&#39;: &#39;AutogluonModels/ag-20230531_211121/models/RandomForestMSE_BAG_L2/&#39;,
  &#39;CatBoost_BAG_L2&#39;: &#39;AutogluonModels/ag-20230531_211121/models/CatBoost_BAG_L2/&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;AutogluonModels/ag-20230531_211121/models/WeightedEnsemble_L3/&#39;},
 &#39;model_fit_times&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: 0.04040360450744629,
  &#39;KNeighborsDist_BAG_L1&#39;: 0.03875446319580078,
  &#39;LightGBMXT_BAG_L1&#39;: 138.23916220664978,
  &#39;LightGBM_BAG_L1&#39;: 62.05918288230896,
  &#39;RandomForestMSE_BAG_L1&#39;: 23.716170072555542,
  &#39;CatBoost_BAG_L1&#39;: 150.33311247825623,
  &#39;ExtraTreesMSE_BAG_L1&#39;: 13.63222599029541,
  &#39;WeightedEnsemble_L2&#39;: 0.39267849922180176,
  &#39;LightGBMXT_BAG_L2&#39;: 45.542848348617554,
  &#39;LightGBM_BAG_L2&#39;: 40.9020471572876,
  &#39;RandomForestMSE_BAG_L2&#39;: 52.730990171432495,
  &#39;CatBoost_BAG_L2&#39;: 51.391669273376465,
  &#39;WeightedEnsemble_L3&#39;: 0.500640869140625},
 &#39;model_pred_times&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: 0.04949808120727539,
  &#39;KNeighborsDist_BAG_L1&#39;: 0.05464935302734375,
  &#39;LightGBMXT_BAG_L1&#39;: 25.574939966201782,
  &#39;LightGBM_BAG_L1&#39;: 5.910081386566162,
  &#39;RandomForestMSE_BAG_L1&#39;: 0.8528399467468262,
  &#39;CatBoost_BAG_L1&#39;: 0.42217397689819336,
  &#39;ExtraTreesMSE_BAG_L1&#39;: 0.659421443939209,
  &#39;WeightedEnsemble_L2&#39;: 0.0009338855743408203,
  &#39;LightGBMXT_BAG_L2&#39;: 1.6702837944030762,
  &#39;LightGBM_BAG_L2&#39;: 0.7125535011291504,
  &#39;RandomForestMSE_BAG_L2&#39;: 0.6861832141876221,
  &#39;CatBoost_BAG_L2&#39;: 0.18214178085327148,
  &#39;WeightedEnsemble_L3&#39;: 0.002357959747314453},
 &#39;num_bag_folds&#39;: 8,
 &#39;max_stack_level&#39;: 3,
 &#39;model_hyperparams&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;KNeighborsDist_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;LightGBMXT_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;RandomForestMSE_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;CatBoost_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;ExtraTreesMSE_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;WeightedEnsemble_L2&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBMXT_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;RandomForestMSE_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;CatBoost_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L3&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True}},
 &#39;leaderboard&#39;:                      model   score_val  pred_time_val    fit_time  \
 0      WeightedEnsemble_L3  -30.346324      36.777124  579.127208   
 1          LightGBM_BAG_L2  -30.629272      34.236158  428.961059   
 2          CatBoost_BAG_L2  -31.035759      33.705746  439.450681   
 3        LightGBMXT_BAG_L2  -31.192608      35.193888  433.601860   
 4   RandomForestMSE_BAG_L2  -31.635988      34.209787  440.790002   
 5      WeightedEnsemble_L2  -32.247750      32.815619  374.779061   
 6          LightGBM_BAG_L1  -33.917339       5.910081   62.059183   
 7        LightGBMXT_BAG_L1  -34.345997      25.574940  138.239162   
 8          CatBoost_BAG_L1  -35.212130       0.422174  150.333112   
 9   RandomForestMSE_BAG_L1  -38.306120       0.852840   23.716170   
 10    ExtraTreesMSE_BAG_L1  -38.311570       0.659421   13.632226   
 11   KNeighborsDist_BAG_L1  -84.125061       0.054649    0.038754   
 12   KNeighborsUnif_BAG_L1 -101.546199       0.049498    0.040404   
 
     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \
 0                 0.002358           0.500641            3       True   
 1                 0.712554          40.902047            2       True   
 2                 0.182142          51.391669            2       True   
 3                 1.670284          45.542848            2       True   
 4                 0.686183          52.730990            2       True   
 5                 0.000934           0.392678            2       True   
 6                 5.910081          62.059183            1       True   
 7                25.574940         138.239162            1       True   
 8                 0.422174         150.333112            1       True   
 9                 0.852840          23.716170            1       True   
 10                0.659421          13.632226            1       True   
 11                0.054649           0.038754            1       True   
 12                0.049498           0.040404            1       True   
 
     fit_order  
 0          13  
 1          10  
 2          12  
 3           9  
 4          11  
 5           8  
 6           4  
 7           3  
 8           6  
 9           5  
 10          7  
 11          2  
 12          1  }</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="65" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:648}" id="sKX0OsZavzzz" data-outputId="68116a0d-bdf9-43f7-f65c-92a57467e422">
<div class="sourceCode" id="cb43"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>predictor_new_features.leaderboard(silent<span class="op">=</span><span class="va">True</span>).plot(kind<span class="op">=</span><span class="st">&quot;bar&quot;</span>, x<span class="op">=</span><span class="st">&quot;model&quot;</span>, y<span class="op">=</span><span class="st">&quot;score_val&quot;</span>)</span></code></pre></div>
<div class="output execute_result" data-execution_count="65">
<pre><code>&lt;Axes: xlabel=&#39;model&#39;&gt;</code></pre>
</div>
<div class="output display_data">
<p><img src="64f8c121f8ea6c360d47638a682f0f2bcef6ae8c.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="59" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:300}" id="8rwvay08VrHD" data-outputId="51005e48-7465-43ec-84bf-c7cf529a1d53">
<div class="sourceCode" id="cb45"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Remember to set all negative values to zero</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>predictions_new_features <span class="op">=</span> pd.DataFrame({<span class="st">&#39;datetime&#39;</span>:test[<span class="st">&#39;datetime&#39;</span>], <span class="st">&#39;count&#39;</span>:predictor_new_features.predict(test)})</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>predictions_new_features[(predictions_new_features[<span class="st">&#39;count&#39;</span>] <span class="op">&lt;</span> <span class="dv">0</span>)] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>predictions_new_features.describe()</span></code></pre></div>
<div class="output execute_result" data-execution_count="59">

  <div id="df-fa1a44ed-0204-42e4-b6f8-1e79ac78a1f0">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>6493.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>162.210129</td>
    </tr>
    <tr>
      <th>std</th>
      <td>142.336899</td>
    </tr>
    <tr>
      <th>min</th>
      <td>2.597392</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>50.300873</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>125.337585</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>231.795502</td>
    </tr>
    <tr>
      <th>max</th>
      <td>821.228027</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-fa1a44ed-0204-42e4-b6f8-1e79ac78a1f0')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-fa1a44ed-0204-42e4-b6f8-1e79ac78a1f0 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-fa1a44ed-0204-42e4-b6f8-1e79ac78a1f0');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell code" data-execution_count="61" id="GhGFr1NRVrHD">
<div class="sourceCode" id="cb46"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Same submitting predictions</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>submission_new_features <span class="op">=</span> pd.read_csv(<span class="st">&#39;submission.csv&#39;</span>)</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>submission_new_features[<span class="st">&quot;count&quot;</span>] <span class="op">=</span> predictions_new_features[<span class="st">&#39;count&#39;</span>]</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>submission_new_features.to_csv(<span class="st">&quot;submission_new_features.csv&quot;</span>, index<span class="op">=</span><span class="va">False</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="62" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="HMHPsxMEVrHD" data-outputId="16956eb7-b920-484b-d111-a1d80f327c22">
<div class="sourceCode" id="cb47"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submit <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">-</span>f submission_new_features.csv <span class="op">-</span>m <span class="st">&quot;new features&quot;</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>100% 188k/188k [00:02&lt;00:00, 71.9kB/s]
Successfully submitted to Bike Sharing Demand</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="63" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="7DfqyKwUVrHD" data-outputId="b3ab7b80-54a3-46f7-f84d-cb578de84708">
<div class="sourceCode" id="cb49"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submissions <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">|</span> tail <span class="op">-</span>n <span class="op">+</span><span class="dv">1</span> <span class="op">|</span> head <span class="op">-</span>n <span class="dv">6</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>fileName                     date                 description           status    publicScore  privateScore  
---------------------------  -------------------  --------------------  --------  -----------  ------------  
submission_new_features.csv  2023-05-31 21:26:52  new features          complete  0.62780      0.62780       
submission.csv               2023-05-31 21:01:25  first raw submission  complete  1.80169      1.80169       
</code></pre>
</div>
</div>
<section id="new-score-of-062780" class="cell markdown" id="MJWd0sm1VrHE">
<h4>New Score of <code>0.62780</code></h4>
</section>
<section id="step-6-hyper-parameter-optimization" class="cell markdown" id="xDm7QKBeVrHE">
<h2>Step 6: Hyper parameter optimization</h2>
<ul>
<li>There are many options for hyper parameter optimization.</li>
<li>Options are to change the AutoGluon higher level parameters or the individual model hyperparameters.</li>
<li>The hyperparameters of the models themselves that are in AutoGluon. Those need the <code>hyperparameter</code> and <code>hyperparameter_tune_kwargs</code> arguments.</li>
</ul>
</section>
<div class="cell code" data-execution_count="70" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000,&quot;referenced_widgets&quot;:[&quot;12d91f2958c9420db693c2f38dde1373&quot;,&quot;16fc82a88cd44dfc9716d141e7363394&quot;,&quot;c43b533b95e046c4b83f5fd26d689d44&quot;,&quot;1ca969c96fab4c25a1a8ecdc74c29d6a&quot;,&quot;74688b88052c4f4c9d5bb6b0e4d9f379&quot;,&quot;8231c70a20f84a76a9dc48c6dc931ad1&quot;,&quot;346ee02fb42c42f180c49c7d335c79f5&quot;,&quot;fdacb9f4a7a94dd7a4269f32644bf21a&quot;,&quot;9b15290866fd4bf38973000b20b21093&quot;,&quot;b53b9e538c814db9b6c2c630d5468caa&quot;,&quot;cd6a39e130284af88911f5bf345ab1f1&quot;,&quot;60c79c0793d84046b6d820cc863b215e&quot;,&quot;04dcf67792aa4ce5ad919aa0c1ce0d79&quot;,&quot;b7c8f03d0f58403fa2907b8c379cb2d2&quot;,&quot;019d827eb1b94020a6245a03c9effe8b&quot;,&quot;45cb4d1daee24647bab22157b10cf59f&quot;,&quot;99181a5862014977877c1dc612b26955&quot;,&quot;4ecf0a737cc24281ba7c7c018c639868&quot;,&quot;f6c933c2be93429f946d089d85ce2bf4&quot;,&quot;e886e50628fc46a88f2fb4d4cc0bb4a0&quot;,&quot;d7d1037fa31048e0bbad7ae9dbb78332&quot;,&quot;4b21bc30d0a04730ae1df8324ea10f76&quot;,&quot;7ecba6ffe67b453d8b2ad0a8ae3c8d6c&quot;,&quot;d60ef43d80ed4edd946b4b289d6a027a&quot;,&quot;04e04c4da2ad47788fa530d4022bd244&quot;,&quot;402811f5b41549c488e7870ea6f5a1cc&quot;,&quot;bce3bc1b0f14440eba5b8aa610a26e9c&quot;,&quot;87e0ccffe8d349af89dac80f135b216c&quot;,&quot;985575eb56cd4cab957264d317bbed5b&quot;,&quot;a982d300bca44cc9ae36349dab69c0be&quot;,&quot;731c14f3f37544abb8ee60184855b408&quot;,&quot;51d87b374d5b46828fab9f7553569a85&quot;,&quot;f23067dc38f242dc86aa5364ac810c43&quot;,&quot;a6c6784b250e4d81ae5b7aa6afcd2345&quot;,&quot;330c52beda2b4c9f888fbebdad1fdaa8&quot;,&quot;7d379828952246e395582cf97c64a535&quot;,&quot;2449ce4b19dd4c699faa318c6e287a75&quot;,&quot;bb1ef0dae9314b919cf72392d26a5254&quot;,&quot;4353803c14a74cd69837f823d1649854&quot;,&quot;2e8c1172c82f4a3d87c3d9c03f7c94df&quot;,&quot;0f42ea3f2bb24ebab2e6f53ef2e3f83b&quot;,&quot;77a9ef2068634221870cd186d9482473&quot;,&quot;f615f22c01c840bea58227169df0a9a6&quot;,&quot;3bfd0343062c4a40927fd88092f046ce&quot;,&quot;ef68af94deb646b29501be7cfa13a8a5&quot;,&quot;ab5f3f50126c4208b61047ffa86edbd6&quot;,&quot;06c14edf1acb4ed8bbafcb7ba3a1d2f5&quot;,&quot;248ac9d7740e413d944673f15f2c5ce8&quot;,&quot;b0a4ee55b31e46a2889a7df76f2903e8&quot;,&quot;d182c62efa004069a60895787ea73619&quot;,&quot;0264ad00b00c43b5b5be598ee23279f6&quot;,&quot;c6a86b0c01c841a4a7e1f37ae36c3cf8&quot;,&quot;f2b93bfc783240b5aa684273c76ac4c9&quot;,&quot;ec7e763bcb664c5ea2c8e63642f9f2cf&quot;,&quot;23327c5f392a401daf21b265b9fd3c73&quot;,&quot;21770f83d0ba405dac815f30fa556d04&quot;,&quot;24928ede77604d35812719587d743bcd&quot;,&quot;c102492072d343009c6129fb9cd455e0&quot;,&quot;976e5701e23f4ab3972996de541ab68c&quot;,&quot;9f4612ce932d40cba0a84a1a847325c5&quot;,&quot;92b31bb6a2ae498ca075f7ecd681e228&quot;,&quot;0ae2dd09be604b5dbaa02167d3199455&quot;,&quot;3accb042c1254184a297c20146541d78&quot;,&quot;766ef39d5fdd46679bccbc01f4a054b4&quot;,&quot;f39e132dc4074c8d88e38e14168cfa5a&quot;,&quot;57c6978cf0d943f2b8aa8b867e90fc6f&quot;]}" id="mSb1ILziVrHE" data-outputId="17db0a1e-893c-4417-f223-3b5af29d3059">
<div class="sourceCode" id="cb51"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autogluon.core <span class="im">as</span> ag</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>nn_hbo <span class="op">=</span> {</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;dropout_prob&#39;</span>: ag.space.Real(<span class="fl">0.0</span>, <span class="fl">0.6</span>, default<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>gpm_hbo <span class="op">=</span> {</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;num_leaves&#39;</span>: ag.space.Int(lower<span class="op">=</span><span class="dv">20</span>,upper<span class="op">=</span><span class="dv">80</span>, default<span class="op">=</span><span class="dv">40</span>)</span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a>hyperparameters<span class="op">=</span> {</span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;CAT&#39;</span>: {<span class="st">&#39;iterations&#39;</span>: <span class="dv">20000</span>},</span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;GBM&#39;</span>: gpm_hbo,</span>
<span id="cb51-13"><a href="#cb51-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;NN_MXNET&#39;</span>: nn_hbo</span>
<span id="cb51-14"><a href="#cb51-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb51-15"><a href="#cb51-15" aria-hidden="true" tabindex="-1"></a>hyperparameter_tune_kwargs<span class="op">=</span> {</span>
<span id="cb51-16"><a href="#cb51-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;num_trials&#39;</span>: <span class="dv">3</span>,</span>
<span id="cb51-17"><a href="#cb51-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;searcher&#39;</span>: <span class="st">&#39;bayes&#39;</span>,</span>
<span id="cb51-18"><a href="#cb51-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;scheduler&#39;</span>: <span class="st">&#39;local&#39;</span></span>
<span id="cb51-19"><a href="#cb51-19" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb51-20"><a href="#cb51-20" aria-hidden="true" tabindex="-1"></a>predictor_new_hpo <span class="op">=</span> TabularPredictor(label<span class="op">=</span><span class="st">&quot;count&quot;</span>, problem_type<span class="op">=</span><span class="st">&quot;regression&quot;</span>, eval_metric<span class="op">=</span><span class="st">&quot;root_mean_squared_error&quot;</span>).fit(train_data<span class="op">=</span>train.drop([<span class="st">&#39;casual&#39;</span>, <span class="st">&#39;registered&#39;</span>], axis<span class="op">=</span><span class="dv">1</span>), time_limit<span class="op">=</span><span class="dv">600</span>, presets<span class="op">=</span><span class="st">&quot;best_quality&quot;</span>, hyperparameters<span class="op">=</span>hyperparameters, hyperparameter_tune_kwargs<span class="op">=</span>hyperparameter_tune_kwargs)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>No path specified. Models will be saved in: &quot;AutogluonModels/ag-20230531_222640/&quot;
Presets specified: [&#39;best_quality&#39;]
Warning: hyperparameter tuning is currently experimental and may cause the process to hang.
Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20
Beginning AutoGluon training ... Time limit = 600s
AutoGluon will save models to &quot;AutogluonModels/ag-20230531_222640/&quot;
AutoGluon Version:  0.7.0
Python Version:     3.10.11
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #1 SMP Sat Apr 29 09:15:28 UTC 2023
Train Data Rows:    10886
Train Data Columns: 13
Label Column: count
Preprocessing data ...
Using Feature Generators to preprocess the data ...
Fitting AutoMLPipelineFeatureGenerator...
	Available Memory:                    10070.36 MB
	Train Data (Original)  Memory Usage: 0.98 MB (0.0% of available memory)
	Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.
	Stage 1 Generators:
		Fitting AsTypeFeatureGenerator...
			Note: Converting 3 features to boolean dtype as they only contain 2 unique values.
	Stage 2 Generators:
		Fitting FillNaFeatureGenerator...
	Stage 3 Generators:
		Fitting IdentityFeatureGenerator...
		Fitting CategoryFeatureGenerator...
			Fitting CategoryMemoryMinimizeFeatureGenerator...
		Fitting DatetimeFeatureGenerator...
	Stage 4 Generators:
		Fitting DropUniqueFeatureGenerator...
	Types of features in original data (raw dtype, special dtypes):
		(&#39;category&#39;, []) : 2 | [&#39;season&#39;, &#39;weather&#39;]
		(&#39;datetime&#39;, []) : 1 | [&#39;datetime&#39;]
		(&#39;float&#39;, [])    : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])      : 7 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;humidity&#39;, &#39;year&#39;, &#39;month&#39;, ...]
	Types of features in processed data (raw dtype, special dtypes):
		(&#39;category&#39;, [])             : 2 | [&#39;season&#39;, &#39;weather&#39;]
		(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])                  : 4 | [&#39;humidity&#39;, &#39;month&#39;, &#39;day&#39;, &#39;hour&#39;]
		(&#39;int&#39;, [&#39;bool&#39;])            : 3 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;year&#39;]
		(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
	0.2s = Fit runtime
	13 features in original data used to generate 17 features in processed data.
	Train Data (Processed) Memory Usage: 1.1 MB (0.0% of available memory)
Data preprocessing and feature engineering runtime = 0.23s ...
AutoGluon will gauge predictive performance using evaluation metric: &#39;root_mean_squared_error&#39;
	This metric&#39;s sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	To change this, specify the eval_metric parameter of Predictor()
AutoGluon will fit 2 stack levels (L1 to L2) ...
Fitting 3 L1 models ...
Hyperparameter tuning model: LightGBM_BAG_L1 ... Tuning model for up to 119.92s of the 599.77s of remaining time.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb53"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;12d91f2958c9420db693c2f38dde1373&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	Stopping HPO to satisfy time limit...
Fitted model: LightGBM_BAG_L1/T1 ...
	-33.8212	 = Validation score   (-root_mean_squared_error)
	95.09s	 = Training   runtime
	0.0s	 = Validation runtime
Hyperparameter tuning model: CatBoost_BAG_L1 ... Tuning model for up to 119.92s of the 504.54s of remaining time.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb55"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;60c79c0793d84046b6d820cc863b215e&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	Stopping HPO to satisfy time limit...
Fitted model: CatBoost_BAG_L1/T1 ...
	-35.7382	 = Validation score   (-root_mean_squared_error)
	129.22s	 = Training   runtime
	0.0s	 = Validation runtime
Hyperparameter tuning model: NeuralNetMXNet_BAG_L1 ... Tuning model for up to 119.92s of the 375.21s of remaining time.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb57"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;7ecba6ffe67b453d8b2ad0a8ae3c8d6c&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
ray::_ray_fit() (pid=46503, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=46503, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
2023-05-31 22:30:35,549	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): ray::_ray_fit() (pid=46504, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
ray::_ray_fit() (pid=46608, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=46608, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-31 22:30:48,279	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=46709, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=46709, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
No model was trained during hyperparameter tuning NeuralNetMXNet_BAG_L1... Skipping this model.
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 347.14s of remaining time.
	-33.0921	 = Validation score   (-root_mean_squared_error)
	0.47s	 = Training   runtime
	0.0s	 = Validation runtime
Fitting 3 L2 models ...
Hyperparameter tuning model: LightGBM_BAG_L2 ... Tuning model for up to 103.99s of the 346.6s of remaining time.
2023-05-31 22:30:54,455	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb59"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;a6c6784b250e4d81ae5b7aa6afcd2345&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	Stopping HPO to satisfy time limit...
Fitted model: LightGBM_BAG_L2/T1 ...
	-34.0426	 = Validation score   (-root_mean_squared_error)
	39.63s	 = Training   runtime
	0.0s	 = Validation runtime
Fitted model: LightGBM_BAG_L2/T2 ...
	-34.4601	 = Validation score   (-root_mean_squared_error)
	37.58s	 = Training   runtime
	0.0s	 = Validation runtime
Hyperparameter tuning model: CatBoost_BAG_L2 ... Tuning model for up to 103.99s of the 269.23s of remaining time.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb61"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;ef68af94deb646b29501be7cfa13a8a5&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	Stopping HPO to satisfy time limit...
Fitted model: CatBoost_BAG_L2/T1 ...
	-33.3975	 = Validation score   (-root_mean_squared_error)
	60.47s	 = Training   runtime
	0.0s	 = Validation runtime
Hyperparameter tuning model: NeuralNetMXNet_BAG_L2 ... Tuning model for up to 103.99s of the 208.67s of remaining time.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb63"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;21770f83d0ba405dac815f30fa556d04&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
ray::_ray_fit() (pid=48218, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=48218, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-31 22:33:21,500	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=48318, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=48318, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-31 22:33:27,587	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=48411, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=48411, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
No model was trained during hyperparameter tuning NeuralNetMXNet_BAG_L2... Skipping this model.
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 185.0s of remaining time.
2023-05-31 22:33:36,443	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
	-33.3719	 = Validation score   (-root_mean_squared_error)
	0.68s	 = Training   runtime
	0.0s	 = Validation runtime
AutoGluon training complete, total runtime = 415.76s ... Best model: &quot;WeightedEnsemble_L2&quot;
TabularPredictor saved. To load, use: predictor = TabularPredictor.load(&quot;AutogluonModels/ag-20230531_222640/&quot;)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="71" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="Clh_VlijVrHE" data-outputId="2e621f58-510c-4192-b128-74d605230365">
<div class="sourceCode" id="cb65"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>predictor_new_hpo.fit_summary()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>*** Summary of fit() ***
Estimated performance of each model:
                 model  score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order
0  WeightedEnsemble_L2 -33.092091       0.001348  224.769623                0.001035           0.466427            2       True          3
1  WeightedEnsemble_L3 -33.371909       0.002144  362.657923                0.001343           0.680709            3       True          7
2   CatBoost_BAG_L2/T1 -33.397486       0.000507  284.773344                0.000194          60.470149            2       True          6
3   LightGBM_BAG_L1/T1 -33.821173       0.000159   95.086985                0.000159          95.086985            1       True          1
4   LightGBM_BAG_L2/T1 -34.042550       0.000454  263.930382                0.000141          39.627187            2       True          4
5   LightGBM_BAG_L2/T2 -34.460148       0.000466  261.879878                0.000153          37.576683            2       True          5
6   CatBoost_BAG_L1/T1 -35.738200       0.000154  129.216211                0.000154         129.216211            1       True          2
Number of models trained: 7
Types of models trained:
{&#39;StackerEnsembleModel_LGB&#39;, &#39;WeightedEnsembleModel&#39;, &#39;StackerEnsembleModel_CatBoost&#39;}
Bagging used: True  (with 8 folds)
Multi-layer stack-ensembling used: True  (with 3 levels)
Feature Metadata (Processed):
(raw dtype, special dtypes):
(&#39;category&#39;, [])             : 2 | [&#39;season&#39;, &#39;weather&#39;]
(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
(&#39;int&#39;, [])                  : 4 | [&#39;humidity&#39;, &#39;month&#39;, &#39;day&#39;, &#39;hour&#39;]
(&#39;int&#39;, [&#39;bool&#39;])            : 3 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;year&#39;]
(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
*** End of fit() summary ***
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.10/dist-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;
  warnings.warn(&#39;AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;&#39;)
</code></pre>
</div>
<div class="output execute_result" data-execution_count="71">
<pre><code>{&#39;model_types&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;CatBoost_BAG_L1/T1&#39;: &#39;StackerEnsembleModel_CatBoost&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;WeightedEnsembleModel&#39;,
  &#39;LightGBM_BAG_L2/T1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L2/T2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;CatBoost_BAG_L2/T1&#39;: &#39;StackerEnsembleModel_CatBoost&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;WeightedEnsembleModel&#39;},
 &#39;model_performance&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: -33.821173461840665,
  &#39;CatBoost_BAG_L1/T1&#39;: -35.7382001729168,
  &#39;WeightedEnsemble_L2&#39;: -33.09209143604683,
  &#39;LightGBM_BAG_L2/T1&#39;: -34.04255022146207,
  &#39;LightGBM_BAG_L2/T2&#39;: -34.460147764655275,
  &#39;CatBoost_BAG_L2/T1&#39;: -33.39748616202508,
  &#39;WeightedEnsemble_L3&#39;: -33.37190901732417},
 &#39;model_best&#39;: &#39;WeightedEnsemble_L2&#39;,
 &#39;model_paths&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: &#39;/content/AutogluonModels/ag-20230531_222640/models/LightGBM_BAG_L1/T1/&#39;,
  &#39;CatBoost_BAG_L1/T1&#39;: &#39;/content/AutogluonModels/ag-20230531_222640/models/CatBoost_BAG_L1/T1/&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;AutogluonModels/ag-20230531_222640/models/WeightedEnsemble_L2/&#39;,
  &#39;LightGBM_BAG_L2/T1&#39;: &#39;/content/AutogluonModels/ag-20230531_222640/models/LightGBM_BAG_L2/T1/&#39;,
  &#39;LightGBM_BAG_L2/T2&#39;: &#39;/content/AutogluonModels/ag-20230531_222640/models/LightGBM_BAG_L2/T2/&#39;,
  &#39;CatBoost_BAG_L2/T1&#39;: &#39;/content/AutogluonModels/ag-20230531_222640/models/CatBoost_BAG_L2/T1/&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;AutogluonModels/ag-20230531_222640/models/WeightedEnsemble_L3/&#39;},
 &#39;model_fit_times&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: 95.08698463439941,
  &#39;CatBoost_BAG_L1/T1&#39;: 129.21621084213257,
  &#39;WeightedEnsemble_L2&#39;: 0.4664270877838135,
  &#39;LightGBM_BAG_L2/T1&#39;: 39.6271870136261,
  &#39;LightGBM_BAG_L2/T2&#39;: 37.576682567596436,
  &#39;CatBoost_BAG_L2/T1&#39;: 60.47014880180359,
  &#39;WeightedEnsemble_L3&#39;: 0.680708646774292},
 &#39;model_pred_times&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: 0.00015878677368164062,
  &#39;CatBoost_BAG_L1/T1&#39;: 0.00015401840209960938,
  &#39;WeightedEnsemble_L2&#39;: 0.0010352134704589844,
  &#39;LightGBM_BAG_L2/T1&#39;: 0.00014138221740722656,
  &#39;LightGBM_BAG_L2/T2&#39;: 0.00015282630920410156,
  &#39;CatBoost_BAG_L2/T1&#39;: 0.00019431114196777344,
  &#39;WeightedEnsemble_L3&#39;: 0.0013427734375},
 &#39;num_bag_folds&#39;: 8,
 &#39;max_stack_level&#39;: 3,
 &#39;model_hyperparams&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;CatBoost_BAG_L1/T1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L2&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2/T1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2/T2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;CatBoost_BAG_L2/T1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L3&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True}},
 &#39;leaderboard&#39;:                  model  score_val  pred_time_val    fit_time  \
 0  WeightedEnsemble_L2 -33.092091       0.001348  224.769623   
 1  WeightedEnsemble_L3 -33.371909       0.002144  362.657923   
 2   CatBoost_BAG_L2/T1 -33.397486       0.000507  284.773344   
 3   LightGBM_BAG_L1/T1 -33.821173       0.000159   95.086985   
 4   LightGBM_BAG_L2/T1 -34.042550       0.000454  263.930382   
 5   LightGBM_BAG_L2/T2 -34.460148       0.000466  261.879878   
 6   CatBoost_BAG_L1/T1 -35.738200       0.000154  129.216211   
 
    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \
 0                0.001035           0.466427            2       True   
 1                0.001343           0.680709            3       True   
 2                0.000194          60.470149            2       True   
 3                0.000159          95.086985            1       True   
 4                0.000141          39.627187            2       True   
 5                0.000153          37.576683            2       True   
 6                0.000154         129.216211            1       True   
 
    fit_order  
 0          3  
 1          7  
 2          6  
 3          1  
 4          4  
 5          5  
 6          2  }</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="73" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:615}" id="VVNIqCEe8npz" data-outputId="e7908d1f-0988-47e3-df90-61ad6b954c84">
<div class="sourceCode" id="cb69"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>predictor_new_hpo.leaderboard(silent<span class="op">=</span><span class="va">True</span>).plot(kind<span class="op">=</span><span class="st">&quot;bar&quot;</span>, x<span class="op">=</span><span class="st">&quot;model&quot;</span>, y<span class="op">=</span><span class="st">&quot;score_val&quot;</span>)</span></code></pre></div>
<div class="output execute_result" data-execution_count="73">
<pre><code>&lt;Axes: xlabel=&#39;model&#39;&gt;</code></pre>
</div>
<div class="output display_data">
<p><img src="6ce1a60acd253498014329d8a66a4ab015fe86d4.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="74" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:300}" id="JzOCamBNVrHE" data-outputId="7fe684f6-07aa-46eb-cdb8-a2151adff91e">
<div class="sourceCode" id="cb71"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Remember to set all negative values to zero</span></span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>predictions_new_hbo <span class="op">=</span> pd.DataFrame({<span class="st">&#39;datetime&#39;</span>:test[<span class="st">&#39;datetime&#39;</span>], <span class="st">&#39;count&#39;</span>:predictor_new_hpo.predict(test)})</span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a>predictions_new_hbo[(predictions_new_hbo[<span class="st">&#39;count&#39;</span>] <span class="op">&lt;</span> <span class="dv">0</span>)] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a>predictions_new_hbo.describe()</span></code></pre></div>
<div class="output execute_result" data-execution_count="74">

  <div id="df-b32de15a-b44a-48f2-af0c-3b198014bce9">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>6493.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>191.745300</td>
    </tr>
    <tr>
      <th>std</th>
      <td>174.427475</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>44.769344</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>150.601822</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>284.679016</td>
    </tr>
    <tr>
      <th>max</th>
      <td>890.347595</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-b32de15a-b44a-48f2-af0c-3b198014bce9')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-b32de15a-b44a-48f2-af0c-3b198014bce9 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-b32de15a-b44a-48f2-af0c-3b198014bce9');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell code" data-execution_count="75" id="9BQnGhoVVrHF">
<div class="sourceCode" id="cb72"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Same submitting predictions</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>submission_new_hpo <span class="op">=</span> pd.read_csv(<span class="st">&#39;submission.csv&#39;</span>)</span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>submission_new_hpo[<span class="st">&quot;count&quot;</span>] <span class="op">=</span> predictions_new_hbo[<span class="st">&#39;count&#39;</span>]</span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>submission_new_hpo.to_csv(<span class="st">&quot;submission_new_hpo.csv&quot;</span>, index<span class="op">=</span><span class="va">False</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="76" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="_eVZVjH2VrHF" data-outputId="24e42cff-7546-43c0-8d93-5c71202a2d2c">
<div class="sourceCode" id="cb73"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submit <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">-</span>f submission_new_hpo.csv <span class="op">-</span>m <span class="st">&quot;new features with hyperparameters&quot;</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>100% 187k/187k [00:03&lt;00:00, 55.8kB/s]
Successfully submitted to Bike Sharing Demand</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="77" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="PeDS8IPFVrHF" data-outputId="f6058a3b-8103-4da1-b847-6300e36c2af0">
<div class="sourceCode" id="cb75"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submissions <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">|</span> tail <span class="op">-</span>n <span class="op">+</span><span class="dv">1</span> <span class="op">|</span> head <span class="op">-</span>n <span class="dv">6</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>fileName                     date                 description                        status    publicScore  privateScore  
---------------------------  -------------------  ---------------------------------  --------  -----------  ------------  
submission_new_hpo.csv       2023-05-31 22:36:55  new features with hyperparameters  complete  0.54816      0.54816       
submission_new_features.csv  2023-05-31 21:26:52  new features                       complete  0.62780      0.62780       
submission.csv               2023-05-31 21:01:25  first raw submission               complete  1.80169      1.80169       
</code></pre>
</div>
</div>
<section id="new-score-of-054816" class="cell markdown" id="kiT4os71VrHF">
<h4>New Score of <code>0.54816</code></h4>
</section>
<section id="step-7-write-a-report" class="cell markdown" id="csCRyLThVrHG">
<h2>Step 7: Write a Report</h2>
<h3 id="refer-to-the-markdown-file-for-the-full-report">Refer to the markdown file for the full report</h3>
<h3 id="creating-plots-and-table-for-report">Creating plots and table for report</h3>
</section>
<div class="cell code" data-execution_count="80" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:542}" id="Zz53e9bzVrHG" data-jupyter="{&quot;source_hidden&quot;:true}" data-outputId="166440ca-f7e9-4090-a156-36dd1948c15a">
<div class="sourceCode" id="cb77"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Taking the top model score from each training run and creating a line plot to show improvement</span></span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a><span class="co"># You can create these in the notebook and save them to PNG or use some other tool (e.g. google sheets, excel)</span></span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> pd.DataFrame(</span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb77-5"><a href="#cb77-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;model&quot;</span>: [<span class="st">&quot;initial&quot;</span>, <span class="st">&quot;add_features&quot;</span>, <span class="st">&quot;hpo&quot;</span>],</span>
<span id="cb77-6"><a href="#cb77-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;score&quot;</span>: [<span class="fl">52.942981</span>, <span class="fl">30.346324</span>, <span class="fl">33.092091</span>]</span>
<span id="cb77-7"><a href="#cb77-7" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb77-8"><a href="#cb77-8" aria-hidden="true" tabindex="-1"></a>).plot(x<span class="op">=</span><span class="st">&quot;model&quot;</span>, y<span class="op">=</span><span class="st">&quot;score&quot;</span>, figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>)).get_figure()</span>
<span id="cb77-9"><a href="#cb77-9" aria-hidden="true" tabindex="-1"></a>fig.savefig(<span class="st">&#39;model_train_score.png&#39;</span>)</span></code></pre></div>
<div class="output display_data">
<p><img src="7d1747a6f4f4089052f729d929127e966d520706.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="81" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:542}" id="GlrmUmTjVrHG" data-outputId="358c9040-6152-420a-e9dd-b947e22e5ab8">
<div class="sourceCode" id="cb78"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Take the 3 kaggle scores and creating a line plot to show improvement</span></span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> pd.DataFrame(</span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;test_eval&quot;</span>: [<span class="st">&quot;initial&quot;</span>, <span class="st">&quot;add_features&quot;</span>, <span class="st">&quot;hpo&quot;</span>],</span>
<span id="cb78-5"><a href="#cb78-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;score&quot;</span>: [<span class="fl">1.80169</span>, <span class="fl">0.62780</span>, <span class="fl">0.54816</span>]</span>
<span id="cb78-6"><a href="#cb78-6" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb78-7"><a href="#cb78-7" aria-hidden="true" tabindex="-1"></a>).plot(x<span class="op">=</span><span class="st">&quot;test_eval&quot;</span>, y<span class="op">=</span><span class="st">&quot;score&quot;</span>, figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>)).get_figure()</span>
<span id="cb78-8"><a href="#cb78-8" aria-hidden="true" tabindex="-1"></a>fig.savefig(<span class="st">&#39;model_test_score.png&#39;</span>)</span></code></pre></div>
<div class="output display_data">
<p><img src="f580ec0f948a8c02cb6afe85a72f86c151bfa625.png" /></p>
</div>
</div>
<section id="hyperparameter-table" class="cell markdown" id="S7JabL4iVrHG">
<h3>Hyperparameter table</h3>
</section>
<div class="cell code" data-execution_count="84" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:204}" id="SomC5seSVrHH" data-outputId="21f9c130-a959-46b8-e5bb-605d231731b4">
<div class="sourceCode" id="cb79"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The 3 hyperparameters we tuned with the kaggle score as the result</span></span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>pd.DataFrame({</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;model&quot;</span>: [<span class="st">&quot;initial&quot;</span>, <span class="st">&quot;add_features&quot;</span>, <span class="st">&quot;hpo&quot;</span>],</span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;hpo1&quot;</span>: [<span class="st">&quot;default&quot;</span>, <span class="st">&quot;default&quot;</span>, <span class="st">&quot;CAT: Number of iterations 20000&quot;</span>],</span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;hpo2&quot;</span>: [<span class="st">&quot;default&quot;</span>, <span class="st">&quot;default&quot;</span>, <span class="st">&quot;NN: Dropout Probability between 0.0 and 0.6&quot;</span>],</span>
<span id="cb79-6"><a href="#cb79-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;hpo3&quot;</span>: [<span class="st">&quot;default&quot;</span>, <span class="st">&quot;default&quot;</span>, <span class="st">&quot;GBM: Number of Leaves between 20 and 80&quot;</span>],</span>
<span id="cb79-7"><a href="#cb79-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;score&quot;</span>: [<span class="fl">1.80169</span>, <span class="fl">0.62780</span>, <span class="fl">0.54816</span>]</span>
<span id="cb79-8"><a href="#cb79-8" aria-hidden="true" tabindex="-1"></a>})</span></code></pre></div>
<div class="output execute_result" data-execution_count="84">

  <div id="df-74736390-668d-465c-8b99-0b3d2a81e6b4">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>model</th>
      <th>hpo1</th>
      <th>hpo2</th>
      <th>hpo3</th>
      <th>score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>initial</td>
      <td>default</td>
      <td>default</td>
      <td>default</td>
      <td>1.80169</td>
    </tr>
    <tr>
      <th>1</th>
      <td>add_features</td>
      <td>default</td>
      <td>default</td>
      <td>default</td>
      <td>0.62780</td>
    </tr>
    <tr>
      <th>2</th>
      <td>hpo</td>
      <td>CAT: Number of iterations 20000</td>
      <td>NN: Dropout Probability between 0.0 and 0.6</td>
      <td>GBM: Number of Leaves between 20 and 80</td>
      <td>0.54816</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-74736390-668d-465c-8b99-0b3d2a81e6b4')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-74736390-668d-465c-8b99-0b3d2a81e6b4 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-74736390-668d-465c-8b99-0b3d2a81e6b4');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
</body>
</html>
